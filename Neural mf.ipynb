{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "another-quarterly",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/eivindfalun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "violent-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version 1.2.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Pandas version\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-likelihood",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eligible-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"addressa_data_preprocessed/\"\n",
    "with open(PATH + \"articles.bin\", \"rb\") as f_in:\n",
    "    articles = pickle.load(f_in)\n",
    "with open(PATH + \"behaviors.bin\", \"rb\") as f_in:\n",
    "    behaviors = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spread-people",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df articles length:  74886\n",
      "Number unique articles:  74886\n",
      "Df behaviors length:  159937\n",
      "Number of unique users 35913\n"
     ]
    }
   ],
   "source": [
    "print(\"Df articles length: \", len(articles))\n",
    "print(\"Number unique articles: \", len(articles[\"article_id\"].unique()))\n",
    "print(\"Df behaviors length: \", len(behaviors))\n",
    "print(\"Number of unique users\", len(behaviors[\"user\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-diameter",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-mortality",
   "metadata": {},
   "source": [
    "## 1.1 Preprocess behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "robust-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if  ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"norwegian\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def text_to_list(text):\n",
    "    text = text.split(\" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "identical-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(df):\n",
    "    df[\"title_cleaned\"] = df.title.apply(func = make_lower_case)\n",
    "    df[\"title_cleaned\"] = df.title_cleaned.apply(func = remove_stop_words)\n",
    "    df[\"title_cleaned\"] = df.title_cleaned.apply(func = remove_punctuation)\n",
    "    return df\n",
    "behaviors = clean_title(behaviors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "retired-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors[\"time\"] = pd.to_datetime(behaviors[\"time\"], unit=\"s\")\n",
    "behaviors[\"author\"].fillna(\"null\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bearing-drive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>title_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6</td>\n",
       "      <td>Slik blir ferieåret 2017</td>\n",
       "      <td>frank lervik</td>\n",
       "      <td>f2ce698b3daf00cfcac0d5279053c4da9de07a92</td>\n",
       "      <td>2017-01-01 17:07:21</td>\n",
       "      <td>ferieåret 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6</td>\n",
       "      <td>Bolig totalskadd i brann</td>\n",
       "      <td>frank lervik</td>\n",
       "      <td>338d849c5c3e0a320d91a2ed2026e43e7c17f8dc</td>\n",
       "      <td>2017-01-01 08:49:47</td>\n",
       "      <td>bolig totalskadd brann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6</td>\n",
       "      <td>Polart lavtrykk med krafig vind og tett snødre...</td>\n",
       "      <td>torsten hanssen</td>\n",
       "      <td>2f467692114ca904797b884155dc0d423b5d9c42</td>\n",
       "      <td>2017-01-01 17:06:26</td>\n",
       "      <td>polart lavtrykk krafig vind tett snødrev treff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6</td>\n",
       "      <td>Nødbluss sendt gjennom vindu startet branntilløp</td>\n",
       "      <td>joakim slettebak wangen</td>\n",
       "      <td>a60c0b9a0ba539404271d0d51ffd209760a42cff</td>\n",
       "      <td>2017-01-01 08:48:51</td>\n",
       "      <td>nødbluss sendt gjennom vindu startet branntilløp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6</td>\n",
       "      <td>Hvem syns du er Årets trønder?</td>\n",
       "      <td>espen rasmussen</td>\n",
       "      <td>ac6aacb71fb09db2bb79554e6bc5ecdb95103ea2</td>\n",
       "      <td>2017-01-01 18:26:23</td>\n",
       "      <td>syns årets trønder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                            userId  \\\n",
       "0    13  cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6   \n",
       "1    13  cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6   \n",
       "2    13  cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6   \n",
       "3    13  cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6   \n",
       "4    13  cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6   \n",
       "\n",
       "                                               title                   author  \\\n",
       "0                           Slik blir ferieåret 2017             frank lervik   \n",
       "1                           Bolig totalskadd i brann             frank lervik   \n",
       "2  Polart lavtrykk med krafig vind og tett snødre...          torsten hanssen   \n",
       "3   Nødbluss sendt gjennom vindu startet branntilløp  joakim slettebak wangen   \n",
       "4                     Hvem syns du er Årets trønder?          espen rasmussen   \n",
       "\n",
       "                                         id                time  \\\n",
       "0  f2ce698b3daf00cfcac0d5279053c4da9de07a92 2017-01-01 17:07:21   \n",
       "1  338d849c5c3e0a320d91a2ed2026e43e7c17f8dc 2017-01-01 08:49:47   \n",
       "2  2f467692114ca904797b884155dc0d423b5d9c42 2017-01-01 17:06:26   \n",
       "3  a60c0b9a0ba539404271d0d51ffd209760a42cff 2017-01-01 08:48:51   \n",
       "4  ac6aacb71fb09db2bb79554e6bc5ecdb95103ea2 2017-01-01 18:26:23   \n",
       "\n",
       "                                       title_cleaned  \n",
       "0                                     ferieåret 2017  \n",
       "1                             bolig totalskadd brann  \n",
       "2  polart lavtrykk krafig vind tett snødrev treff...  \n",
       "3   nødbluss sendt gjennom vindu startet branntilløp  \n",
       "4                                 syns årets trønder  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviors.drop(columns=[\"userFreq\", \"articleId\"], inplace=True)\n",
    "behaviors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "specific-ribbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159937\n",
      "125854\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>title_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6</td>\n",
       "      <td>Slik blir ferieåret 2017</td>\n",
       "      <td>frank lervik</td>\n",
       "      <td>f2ce698b3daf00cfcac0d5279053c4da9de07a92</td>\n",
       "      <td>2017-01-01 17:07:21</td>\n",
       "      <td>ferieåret 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6</td>\n",
       "      <td>Bolig totalskadd i brann</td>\n",
       "      <td>frank lervik</td>\n",
       "      <td>338d849c5c3e0a320d91a2ed2026e43e7c17f8dc</td>\n",
       "      <td>2017-01-01 08:49:47</td>\n",
       "      <td>bolig totalskadd brann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6</td>\n",
       "      <td>Polart lavtrykk med krafig vind og tett snødre...</td>\n",
       "      <td>torsten hanssen</td>\n",
       "      <td>2f467692114ca904797b884155dc0d423b5d9c42</td>\n",
       "      <td>2017-01-01 17:06:26</td>\n",
       "      <td>polart lavtrykk krafig vind tett snødrev treff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6</td>\n",
       "      <td>Nødbluss sendt gjennom vindu startet branntilløp</td>\n",
       "      <td>joakim slettebak wangen</td>\n",
       "      <td>a60c0b9a0ba539404271d0d51ffd209760a42cff</td>\n",
       "      <td>2017-01-01 08:48:51</td>\n",
       "      <td>nødbluss sendt gjennom vindu startet branntilløp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6</td>\n",
       "      <td>Hvem syns du er Årets trønder?</td>\n",
       "      <td>espen rasmussen</td>\n",
       "      <td>ac6aacb71fb09db2bb79554e6bc5ecdb95103ea2</td>\n",
       "      <td>2017-01-01 18:26:23</td>\n",
       "      <td>syns årets trønder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                            userId  \\\n",
       "0    13  cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6   \n",
       "1    13  cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6   \n",
       "2    13  cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6   \n",
       "3    13  cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6   \n",
       "4    13  cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6   \n",
       "\n",
       "                                               title                   author  \\\n",
       "0                           Slik blir ferieåret 2017             frank lervik   \n",
       "1                           Bolig totalskadd i brann             frank lervik   \n",
       "2  Polart lavtrykk med krafig vind og tett snødre...          torsten hanssen   \n",
       "3   Nødbluss sendt gjennom vindu startet branntilløp  joakim slettebak wangen   \n",
       "4                     Hvem syns du er Årets trønder?          espen rasmussen   \n",
       "\n",
       "                                         id                time  \\\n",
       "0  f2ce698b3daf00cfcac0d5279053c4da9de07a92 2017-01-01 17:07:21   \n",
       "1  338d849c5c3e0a320d91a2ed2026e43e7c17f8dc 2017-01-01 08:49:47   \n",
       "2  2f467692114ca904797b884155dc0d423b5d9c42 2017-01-01 17:06:26   \n",
       "3  a60c0b9a0ba539404271d0d51ffd209760a42cff 2017-01-01 08:48:51   \n",
       "4  ac6aacb71fb09db2bb79554e6bc5ecdb95103ea2 2017-01-01 18:26:23   \n",
       "\n",
       "                                       title_cleaned  \n",
       "0                                     ferieåret 2017  \n",
       "1                             bolig totalskadd brann  \n",
       "2  polart lavtrykk krafig vind tett snødrev treff...  \n",
       "3   nødbluss sendt gjennom vindu startet branntilløp  \n",
       "4                                 syns årets trønder  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(behaviors))\n",
    "sub_behaviors = behaviors[behaviors.groupby('user').user.transform('count')>3].copy()\n",
    "print(len(sub_behaviors))\n",
    "sub_behaviors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-cancer",
   "metadata": {},
   "source": [
    "## 1.2 Preprocess articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "centered-traffic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>kw_category</th>\n",
       "      <th>article</th>\n",
       "      <th>title_cleaned</th>\n",
       "      <th>category_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcc01a7a1a7f7092a2da6b9c5186fdef421c8ab6</td>\n",
       "      <td>pål solberg</td>\n",
       "      <td>Det er Trøndelag politidistrikt som klokken 1...</td>\n",
       "      <td>- Dette er ingen lekeplass</td>\n",
       "      <td>http://www.adressa.no/nyheter/sortrondelag/201...</td>\n",
       "      <td>nyheter sortrondelag</td>\n",
       "      <td>73905</td>\n",
       "      <td>lekeplass</td>\n",
       "      <td>[nyheter, sortrondelag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e1c14c3f599c9764a003740b9959c4e6f2fbc8e3</td>\n",
       "      <td>empty</td>\n",
       "      <td>Det er Trøndelag Veteranvognklubb TVK som for...</td>\n",
       "      <td>Trondheim fylles med veteranbiler</td>\n",
       "      <td>http://www.adressa.no/bil/veteran/article80867...</td>\n",
       "      <td>bil veteran</td>\n",
       "      <td>65918</td>\n",
       "      <td>trondheim fylles veteranbiler</td>\n",
       "      <td>[bil, veteran]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6a0612e60690288a776834811004ce133f326cee</td>\n",
       "      <td>annemona grann</td>\n",
       "      <td>Historiene er nesten for utrolige og rommer e...</td>\n",
       "      <td>- Historiene er nesten for utrolige</td>\n",
       "      <td>http://www.adressa.no/kultur/2015/11/06/Histor...</td>\n",
       "      <td>kultur</td>\n",
       "      <td>30909</td>\n",
       "      <td>historiene nesten utrolige</td>\n",
       "      <td>[kultur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13eb96b4cfbbc5954c54a75737afcac5ccc61779</td>\n",
       "      <td>elin fosshaug olsø</td>\n",
       "      <td>Flere bilførere reagerte med aggressiv kjørin...</td>\n",
       "      <td>Bilister aggressive mot trafikkaksjon</td>\n",
       "      <td>http://www.adressa.no/nyheter/trondheim/articl...</td>\n",
       "      <td>nyheter trondheim</td>\n",
       "      <td>5855</td>\n",
       "      <td>bilister aggressive trafikkaksjon</td>\n",
       "      <td>[nyheter, trondheim]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b40a30877124510cf65683b6c9391d927e20f89d</td>\n",
       "      <td>ann iren bævre</td>\n",
       "      <td>Under årets store interiørmesse i Milano var ...</td>\n",
       "      <td>Fyll på med småbord</td>\n",
       "      <td>http://www.adressa.no/forbruker/hjem/article15...</td>\n",
       "      <td>forbruker hjem</td>\n",
       "      <td>52530</td>\n",
       "      <td>fyll småbord</td>\n",
       "      <td>[forbruker, hjem]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 article_id              author  \\\n",
       "0  fcc01a7a1a7f7092a2da6b9c5186fdef421c8ab6         pål solberg   \n",
       "1  e1c14c3f599c9764a003740b9959c4e6f2fbc8e3               empty   \n",
       "2  6a0612e60690288a776834811004ce133f326cee      annemona grann   \n",
       "3  13eb96b4cfbbc5954c54a75737afcac5ccc61779  elin fosshaug olsø   \n",
       "4  b40a30877124510cf65683b6c9391d927e20f89d      ann iren bævre   \n",
       "\n",
       "                                                body  \\\n",
       "0   Det er Trøndelag politidistrikt som klokken 1...   \n",
       "1   Det er Trøndelag Veteranvognklubb TVK som for...   \n",
       "2   Historiene er nesten for utrolige og rommer e...   \n",
       "3   Flere bilførere reagerte med aggressiv kjørin...   \n",
       "4   Under årets store interiørmesse i Milano var ...   \n",
       "\n",
       "                                   title  \\\n",
       "0             - Dette er ingen lekeplass   \n",
       "1      Trondheim fylles med veteranbiler   \n",
       "2    - Historiene er nesten for utrolige   \n",
       "3  Bilister aggressive mot trafikkaksjon   \n",
       "4                    Fyll på med småbord   \n",
       "\n",
       "                                                 url            kw_category  \\\n",
       "0  http://www.adressa.no/nyheter/sortrondelag/201...  nyheter sortrondelag    \n",
       "1  http://www.adressa.no/bil/veteran/article80867...           bil veteran    \n",
       "2  http://www.adressa.no/kultur/2015/11/06/Histor...                 kultur   \n",
       "3  http://www.adressa.no/nyheter/trondheim/articl...     nyheter trondheim    \n",
       "4  http://www.adressa.no/forbruker/hjem/article15...        forbruker hjem    \n",
       "\n",
       "   article                      title_cleaned    category_preprocessed  \n",
       "0    73905                          lekeplass  [nyheter, sortrondelag]  \n",
       "1    65918      trondheim fylles veteranbiler           [bil, veteran]  \n",
       "2    30909         historiene nesten utrolige                 [kultur]  \n",
       "3     5855  bilister aggressive trafikkaksjon     [nyheter, trondheim]  \n",
       "4    52530                       fyll småbord        [forbruker, hjem]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-chicago",
   "metadata": {},
   "source": [
    "### 1.2.1 One-hot-encode authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "central-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_authors_unique(df, column):\n",
    "    authors = []\n",
    "    \n",
    "    def extract_authors(_list):\n",
    "        for elem in _list:\n",
    "            if isinstance(elem, list):\n",
    "                extract_authors(elem)\n",
    "            else:\n",
    "                if elem not in authors:\n",
    "                    authors.append(elem)\n",
    "    extract_authors(df[column].values)\n",
    "    return authors\n",
    "    \n",
    "authors = gen_authors_unique(articles, \"author\")\n",
    "authors_to_id = {name: idx for idx, name in enumerate(authors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "immediate-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_list = []\n",
    "for idx, val in enumerate(articles[\"author\"].values):\n",
    "    try:\n",
    "        authors_list.append(authors_to_id[val])\n",
    "    except:\n",
    "        # Val is a list; the article is written by multiple article. I append the first author in the list\n",
    "        authors_list.append(authors_to_id[val[0]])\n",
    "articles[\"authors_onehot\"] = authors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "occupational-whale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are:  6319  unique authors\n"
     ]
    }
   ],
   "source": [
    "num_authors = len(authors_to_id)\n",
    "print(\"There are: \", num_authors, \" unique authors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-material",
   "metadata": {},
   "source": [
    "### 1.2.2 Tokenize titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "composed-rochester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4647]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = articles[\"title_cleaned\"]\n",
    "title_tokenizer = Tokenizer()\n",
    "title_tokenizer.fit_on_texts(titles)\n",
    "titles_to_num = title_tokenizer.texts_to_sequences(titles)\n",
    "maxlen=300\n",
    "vocab_size = len(title_tokenizer.word_index)  + 1\n",
    "titles_to_num[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "numeric-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = dict(map(reversed, title_tokenizer.word_index.items()))\n",
    "reverse_word_map[0] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "renewable-welcome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4647, 0, 0, 0, 0, 0],\n",
       " [1, 6236, 15565, 0, 0, 0],\n",
       " [6237, 94, 4648, 0, 0, 0],\n",
       " [1351, 11799, 23537, 0, 0, 0],\n",
       " [3467, 23538, 0, 0, 0, 0],\n",
       " [1626, 5610, 3718, 0, 0, 0],\n",
       " [2896, 436, 23539, 295, 0, 0],\n",
       " [53, 23540, 2897, 2741, 0, 0],\n",
       " [5090, 5611, 0, 0, 0, 0],\n",
       " [215, 15566, 1431, 0, 0, 0],\n",
       " [3051, 2065, 42, 901, 948, 0],\n",
       " [365, 7053, 536, 0, 0, 0],\n",
       " [3468, 23541, 0, 0, 0, 0],\n",
       " [76, 1042, 23542, 0, 0, 0],\n",
       " [409, 244, 46, 8140, 1884, 0],\n",
       " [4, 377, 1688, 1, 0, 0],\n",
       " [536, 9582, 4, 11800, 0, 0],\n",
       " [528, 11801, 0, 0, 0, 0],\n",
       " [730, 23543, 997, 1043, 11802, 0],\n",
       " [325, 106, 3469, 15567, 4649, 998],\n",
       " [1885, 21, 165, 1383, 3470, 0],\n",
       " [23544, 567, 0, 0, 0, 0],\n",
       " [1886, 23545, 15568, 0, 0, 0],\n",
       " [780, 391, 23546, 352, 0, 0],\n",
       " [1197, 133, 2469, 0, 0, 0],\n",
       " [59, 8141, 9583, 23547, 1229, 23548],\n",
       " [681, 321, 5612, 10, 180, 227],\n",
       " [11803, 126, 3242, 6238, 1523, 0],\n",
       " [228, 7054, 11804, 3243, 23549, 0],\n",
       " [100, 7, 11805, 23550, 1, 1689],\n",
       " [1806, 23551, 0, 0, 0, 0],\n",
       " [4295, 15569, 162, 2742, 0, 0],\n",
       " [6, 11806, 2470, 0, 0, 0],\n",
       " [11807, 8142, 8143, 0, 0, 0],\n",
       " [23552, 2898, 55, 949, 0, 0],\n",
       " [49, 138, 5091, 0, 0, 0],\n",
       " [39, 4296, 478, 8144, 353, 0],\n",
       " [127, 1198, 461, 588, 7055, 0],\n",
       " [811, 9584, 847, 23553, 0, 0],\n",
       " [23554, 15570, 38, 193, 0, 0],\n",
       " [4650, 356, 1303, 0, 0, 0],\n",
       " [10, 441, 23555, 811, 15571, 0],\n",
       " [11808, 1304, 522, 0, 0, 0],\n",
       " [225, 1103, 23556, 0, 0, 0],\n",
       " [6, 3052, 2261, 23557, 0, 0],\n",
       " [232, 36, 3719, 3244, 7056, 0],\n",
       " [79, 613, 97, 20, 0, 0],\n",
       " [43, 326, 5092, 1, 0, 0],\n",
       " [969, 354, 950, 2600, 0, 0],\n",
       " [8, 3994, 236, 11809, 80, 0],\n",
       " [276, 107, 1887, 14, 107, 441],\n",
       " [6239, 79, 759, 0, 0, 0],\n",
       " [4651, 23558, 7057, 205, 1571, 23559],\n",
       " [3995, 0, 0, 0, 0, 0],\n",
       " [53, 1199, 11810, 0, 0, 0],\n",
       " [15572, 1230, 3245, 0, 0, 0],\n",
       " [3720, 11811, 8, 0, 0, 0],\n",
       " [2066, 1888, 15573, 0, 0, 0],\n",
       " [11812, 169, 3053, 0, 0, 0],\n",
       " [97, 108, 61, 456, 631, 0],\n",
       " [4652, 309, 213, 194, 2262, 72],\n",
       " [666, 7058, 21, 3996, 5613, 0],\n",
       " [744, 4297, 1807, 0, 0, 0],\n",
       " [23560, 11813, 0, 0, 0, 0],\n",
       " [23561, 23562, 23563, 0, 0, 0],\n",
       " [1231, 366, 367, 23564, 0, 0],\n",
       " [10, 15574, 7059, 1168, 0, 0],\n",
       " [1572, 15575, 0, 0, 0, 0],\n",
       " [4653, 2263, 233, 549, 6, 170],\n",
       " [1627, 457, 9585, 0, 0, 0],\n",
       " [4298, 28, 1136, 0, 0, 0],\n",
       " [15576, 5093, 2361, 2264, 15577, 0],\n",
       " [1970, 5614, 15578, 0, 0, 0],\n",
       " [1889, 23565, 0, 0, 0, 0],\n",
       " [682, 2151, 23566, 23, 631, 528],\n",
       " [23567, 11814, 0, 0, 0, 0],\n",
       " [23568, 8145, 101, 23569, 0, 0],\n",
       " [2267, 3471, 11815, 0, 0, 0],\n",
       " [23570, 3054, 0, 0, 0, 0],\n",
       " [11816, 23571, 82, 23572, 0, 0],\n",
       " [7060, 16, 3055, 0, 0, 0],\n",
       " [1, 1971, 138, 429, 0, 0],\n",
       " [252, 92, 2263, 549, 1, 577],\n",
       " [193, 11817, 0, 0, 0, 0],\n",
       " [745, 181, 151, 318, 714, 15],\n",
       " [11818, 1305, 11819, 0, 0, 0],\n",
       " [15579, 140, 23573, 15580, 115, 0],\n",
       " [9586, 23574, 1, 0, 0, 0],\n",
       " [3472, 23575, 88, 23576, 259, 9587],\n",
       " [107, 14, 327, 154, 0, 0],\n",
       " [33, 1104, 3997, 2472, 0, 0],\n",
       " [695, 760, 1072, 0, 0, 0],\n",
       " [36, 63, 9588, 8146, 0, 0],\n",
       " [8147, 902, 6241, 23577, 0, 0],\n",
       " [23578, 20, 0, 0, 0, 0],\n",
       " [23579, 1168, 0, 0, 0, 0],\n",
       " [11820, 7061, 0, 0, 0, 0],\n",
       " [9589, 15581, 999, 0, 0, 0],\n",
       " [386, 23580, 23581, 0, 0, 0],\n",
       " [4, 23582, 2473, 746, 15582, 23583],\n",
       " [23584, 8148, 8149, 8150, 39, 0],\n",
       " [36, 373, 23585, 14, 282, 0],\n",
       " [23586, 23587, 276, 0, 0, 0],\n",
       " [15583, 9590, 29, 4654, 0, 0],\n",
       " [23588, 9, 2152, 597, 3, 0],\n",
       " [578, 6242, 23589, 9591, 118, 9592],\n",
       " [1524, 5094, 11821, 95, 0, 0],\n",
       " [3473, 3056, 53, 6243, 0, 0],\n",
       " [23590, 23591, 0, 0, 0, 0],\n",
       " [3057, 127, 23592, 11822, 731, 0],\n",
       " [2474, 145, 3721, 11823, 0, 0],\n",
       " [23593, 3998, 3247, 0, 0, 0],\n",
       " [15584, 847, 23594, 7062, 3722, 0],\n",
       " [447, 1525, 5095, 2268, 0, 0],\n",
       " [374, 1628, 1432, 2362, 1169, 5096],\n",
       " [116, 1073, 0, 0, 0, 0],\n",
       " [1808, 3999, 23595, 64, 14, 4299],\n",
       " [4655, 3248, 410, 2601, 3249, 0],\n",
       " [951, 4300, 4, 8151, 50, 78],\n",
       " [2743, 43, 613, 14, 1074, 5],\n",
       " [6244, 23596, 1690, 1526, 23597, 0],\n",
       " [23598, 2744, 1352, 147, 56, 970],\n",
       " [102, 9593, 2363, 0, 0, 0],\n",
       " [23599, 1, 0, 0, 0, 0],\n",
       " [11824, 84, 8152, 386, 131, 442],\n",
       " [4301, 795, 9594, 4302, 14, 346],\n",
       " [1691, 4656, 0, 0, 0, 0],\n",
       " [6245, 23600, 15585, 0, 0, 0],\n",
       " [1433, 5098, 15586, 0, 0, 0],\n",
       " [2745, 1229, 1, 0, 0, 0],\n",
       " [4000, 1527, 15587, 0, 0, 0],\n",
       " [15588, 715, 2, 970, 796, 15589],\n",
       " [2473, 23601, 341, 7, 469, 0],\n",
       " [23602, 1629, 0, 0, 0, 0],\n",
       " [11825, 247, 1137, 0, 0, 0],\n",
       " [23603, 216, 3474, 0, 0, 0],\n",
       " [6, 46, 23604, 54, 23605, 0],\n",
       " [9595, 23606, 3475, 0, 0, 0],\n",
       " [732, 35, 347, 11826, 0, 0],\n",
       " [1809, 848, 5099, 2154, 6, 347],\n",
       " [1972, 2269, 0, 0, 0, 0],\n",
       " [139, 598, 8153, 1000, 0, 0],\n",
       " [15590, 24, 6246, 0, 0, 0],\n",
       " [9596, 8154, 6247, 0, 0, 0],\n",
       " [66, 111, 328, 98, 0, 0],\n",
       " [657, 1630, 1973, 189, 23607, 642],\n",
       " [9597, 23608, 971, 972, 5100, 3058],\n",
       " [162, 3, 348, 23609, 23610, 0],\n",
       " [683, 23611, 8155, 0, 0, 0],\n",
       " [1809, 2602, 4303, 6248, 4001, 0],\n",
       " [2270, 23612, 15591, 15592, 332, 0],\n",
       " [34, 1200, 11, 0, 0, 0],\n",
       " [34, 1746, 4304, 1306, 126, 310],\n",
       " [99, 829, 0, 0, 0, 0],\n",
       " [23613, 20, 0, 0, 0, 0],\n",
       " [9598, 81, 40, 23614, 0, 0],\n",
       " [797, 23615, 23616, 0, 0, 0],\n",
       " [206, 3723, 23617, 847, 0, 0],\n",
       " [6249, 7063, 60, 23618, 23619, 23620],\n",
       " [186, 11, 15593, 23621, 0, 0],\n",
       " [3250, 8156, 623, 973, 1138, 0],\n",
       " [118, 849, 106, 489, 0, 0],\n",
       " [349, 18, 4657, 0, 0, 0],\n",
       " [32, 23622, 23623, 0, 0, 0],\n",
       " [7064, 4002, 926, 0, 0, 0],\n",
       " [504, 2746, 15594, 0, 0, 0],\n",
       " [1974, 333, 3251, 23624, 2271, 9599],\n",
       " [11827, 463, 6250, 23625, 1528, 441],\n",
       " [3252, 23626, 0, 0, 0, 0],\n",
       " [430, 23627, 4658, 1810, 0, 0],\n",
       " [2747, 6251, 69, 624, 1631, 448],\n",
       " [490, 6252, 7, 9600, 0, 0],\n",
       " [732, 23628, 0, 0, 0, 0],\n",
       " [3724, 15595, 0, 0, 0, 0],\n",
       " [4305, 52, 9601, 44, 1975, 716],\n",
       " [1232, 1811, 23629, 11829, 0, 0],\n",
       " [35, 61, 9602, 2741, 5615, 0],\n",
       " [6253, 3725, 7065, 0, 0, 0],\n",
       " [9603, 0, 0, 0, 0, 0],\n",
       " [6254, 1001, 11830, 0, 0, 0],\n",
       " [90, 23630, 182, 0, 0, 0],\n",
       " [2603, 322, 15596, 0, 0, 0],\n",
       " [4306, 513, 1353, 69, 513, 12],\n",
       " [137, 137, 798, 0, 0, 0],\n",
       " [485, 9604, 15597, 0, 0, 0],\n",
       " [8157, 1201, 903, 1890, 0, 0],\n",
       " [1002, 5101, 18, 47, 248, 0],\n",
       " [23631, 4659, 9605, 0, 0, 0],\n",
       " [8158, 1003, 15598, 2476, 0, 0],\n",
       " [557, 133, 2155, 6255, 0, 0],\n",
       " [1075, 3726, 11831, 0, 0, 0],\n",
       " [1571, 15599, 7066, 3059, 3253, 9],\n",
       " [486, 3060, 904, 3254, 23632, 974],\n",
       " [537, 902, 1573, 23633, 0, 0],\n",
       " [632, 667, 23634, 332, 0, 0],\n",
       " [203, 23635, 23636, 0, 0, 0],\n",
       " [11832, 15600, 23637, 0, 0, 0],\n",
       " [225, 4307, 1232, 0, 0, 0],\n",
       " [859, 733, 928, 0, 0, 0],\n",
       " [23638, 15601, 2477, 1574, 0, 0],\n",
       " [1074, 209, 15602, 271, 0, 0],\n",
       " [66, 3061, 4660, 23639, 0, 0],\n",
       " [5617, 89, 11833, 23640, 0, 0],\n",
       " [4003, 696, 69, 5102, 23641, 7067],\n",
       " [365, 68, 1890, 0, 0, 0],\n",
       " [411, 274, 449, 0, 0, 0],\n",
       " [257, 7068, 1, 0, 0, 0],\n",
       " [6256, 882, 99, 0, 0, 0],\n",
       " [205, 5618, 1434, 0, 0, 0],\n",
       " [2899, 15603, 4661, 11834, 1891, 0],\n",
       " [486, 643, 82, 4662, 1747, 902],\n",
       " [159, 299, 514, 3727, 4308, 0],\n",
       " [40, 589, 6257, 0, 0, 0],\n",
       " [374, 1307, 426, 23642, 3062, 0],\n",
       " [45, 474, 9606, 306, 799, 53],\n",
       " [357, 40, 1892, 0, 0, 0],\n",
       " [23643, 9, 975, 61, 3, 1482],\n",
       " [245, 1529, 367, 1, 0, 0],\n",
       " [9607, 8159, 23644, 108, 165, 0],\n",
       " [23645, 557, 1435, 0, 0, 0],\n",
       " [10, 697, 329, 781, 379, 1530],\n",
       " [15604, 11835, 0, 0, 0, 0],\n",
       " [4004, 1976, 3476, 1198, 0, 0],\n",
       " [23646, 23647, 1384, 23648, 0, 0],\n",
       " [1202, 23649, 2748, 0, 0, 0],\n",
       " [23650, 23651, 469, 0, 0, 0],\n",
       " [25, 1632, 3728, 233, 15605, 0],\n",
       " [23652, 33, 0, 0, 0, 0],\n",
       " [599, 334, 902, 0, 0, 0],\n",
       " [1385, 5103, 157, 2069, 0, 0],\n",
       " [487, 9608, 4663, 479, 157, 0],\n",
       " [2156, 8160, 4309, 515, 23653, 0],\n",
       " [811, 4005, 2604, 4664, 9609, 0],\n",
       " [23654, 23655, 160, 449, 0, 0],\n",
       " [15606, 15607, 1, 0, 0, 0],\n",
       " [62, 8161, 23656, 0, 0, 0],\n",
       " [734, 23657, 0, 0, 0, 0],\n",
       " [23658, 124, 0, 0, 0, 0],\n",
       " [335, 30, 11836, 1, 0, 0],\n",
       " [23659, 1893, 514, 0, 0, 0],\n",
       " [23660, 16, 684, 1894, 0, 0],\n",
       " [4310, 2364, 0, 0, 0, 0],\n",
       " [23661, 18, 11837, 15608, 23662, 0],\n",
       " [11838, 215, 488, 0, 0, 0],\n",
       " [1977, 15609, 32, 1139, 1895, 0],\n",
       " [15610, 8162, 259, 15611, 0, 0],\n",
       " [1812, 761, 23663, 4006, 15612, 2478],\n",
       " [23664, 1045, 0, 0, 0, 0],\n",
       " [279, 67, 3477, 2157, 5619, 1978],\n",
       " [2070, 377, 644, 80, 1386, 0],\n",
       " [39, 81, 236, 1436, 7069, 9610],\n",
       " [1268, 31, 3478, 23665, 0, 0],\n",
       " [8, 47, 4311, 2365, 7070, 0],\n",
       " [35, 23666, 1525, 15613, 0, 0],\n",
       " [316, 409, 123, 30, 22, 1308],\n",
       " [2749, 23667, 9, 9611, 28, 0],\n",
       " [65, 11839, 1573, 11840, 15614, 0],\n",
       " [1076, 7071, 1203, 15615, 5, 62],\n",
       " [1269, 3479, 0, 0, 0, 0],\n",
       " [18, 1270, 23668, 23669, 8, 0],\n",
       " [8163, 4312, 9612, 0, 0, 0],\n",
       " [4313, 9613, 2158, 262, 11841, 15616],\n",
       " [8164, 154, 1529, 8, 0, 0],\n",
       " [11842, 1813, 11843, 0, 0, 0],\n",
       " [172, 7, 15617, 1748, 126, 1980],\n",
       " [800, 9, 67, 19, 1004, 2366],\n",
       " [623, 5105, 883, 15618, 0, 0],\n",
       " [1104, 7072, 0, 0, 0, 0],\n",
       " [374, 470, 516, 600, 475, 658],\n",
       " [4314, 1531, 11844, 7075, 0, 0],\n",
       " [11845, 6260, 11846, 253, 8165, 0],\n",
       " [4007, 8166, 2751, 5107, 6261, 0],\n",
       " [6262, 330, 5622, 0, 0, 0],\n",
       " [2479, 23671, 0, 0, 0, 0],\n",
       " [4666, 23672, 299, 0, 0, 0],\n",
       " [682, 1434, 1982, 55, 2752, 0],\n",
       " [23673, 2071, 176, 2, 23674, 782],\n",
       " [23675, 53, 5108, 0, 0, 0],\n",
       " [5109, 1437, 2, 14, 0, 0],\n",
       " [884, 2367, 1529, 4315, 1235, 0],\n",
       " [2072, 401, 1438, 2753, 0, 0],\n",
       " [4316, 21, 1814, 971, 0, 0],\n",
       " [15619, 387, 0, 0, 0, 0],\n",
       " [45, 3480, 23676, 0, 0, 0],\n",
       " [119, 23677, 5623, 33, 11847, 368],\n",
       " [8, 7076, 1, 9615, 11848, 0],\n",
       " [698, 103, 3257, 63, 5110, 0],\n",
       " [6263, 601, 3, 55, 9616, 860],\n",
       " [15620, 4667, 15621, 1633, 0, 0],\n",
       " [1983, 3729, 471, 905, 0, 0],\n",
       " [6264, 11849, 38, 0, 0, 0],\n",
       " [861, 1896, 5111, 1984, 0, 0],\n",
       " [40, 2073, 0, 0, 0, 0],\n",
       " [240, 3730, 15622, 4317, 0, 0],\n",
       " [23678, 2159, 165, 0, 0, 0],\n",
       " [1204, 112, 464, 0, 0, 0],\n",
       " [23679, 4668, 0, 0, 0, 0],\n",
       " [5090, 9617, 0, 0, 0, 0],\n",
       " [33, 2368, 9618, 0, 0, 0],\n",
       " [1985, 2272, 6, 1046, 1692, 0],\n",
       " [162, 283, 365, 8167, 177, 80],\n",
       " [23680, 760, 885, 23681, 23682, 0],\n",
       " [193, 186, 210, 0, 0, 0],\n",
       " [25, 23683, 332, 49, 5, 1140],\n",
       " [23684, 1532, 3, 0, 0, 0],\n",
       " [568, 9619, 11850, 850, 633, 0],\n",
       " [2480, 110, 236, 4008, 1271, 0],\n",
       " [23685, 1105, 4669, 9620, 11851, 23686],\n",
       " [696, 27, 6265, 0, 0, 0],\n",
       " [4, 3481, 886, 0, 0, 0],\n",
       " [472, 1106, 1897, 23687, 276, 0],\n",
       " [5112, 2273, 18, 0, 0, 0],\n",
       " [8, 128, 887, 237, 0, 0],\n",
       " [284, 3482, 2074, 3483, 15623, 0],\n",
       " [1047, 1387, 1, 1387, 166, 0],\n",
       " [23688, 9621, 0, 0, 0, 0],\n",
       " [5624, 15624, 23689, 0, 0, 0],\n",
       " [1000, 412, 17, 183, 717, 0],\n",
       " [6266, 1439, 0, 0, 0, 0],\n",
       " [60, 93, 15625, 23690, 0, 0],\n",
       " [9622, 25, 783, 569, 4318, 14],\n",
       " [23691, 8168, 0, 0, 0, 0],\n",
       " [4305, 68, 301, 8169, 0, 0],\n",
       " [23692, 2481, 8170, 0, 0, 0],\n",
       " [976, 23693, 5625, 0, 0, 0],\n",
       " [23694, 3063, 972, 645, 0, 0],\n",
       " [4319, 1693, 597, 1986, 7077, 3258],\n",
       " [3484, 43, 446, 156, 352, 1749],\n",
       " [4, 1138, 66, 2160, 762, 0],\n",
       " [6267, 5626, 0, 0, 0, 0],\n",
       " [23695, 2605, 0, 0, 0, 0],\n",
       " [9623, 1987, 45, 20, 0, 0],\n",
       " [3485, 8171, 23696, 0, 0, 0],\n",
       " [1694, 15626, 0, 0, 0, 0],\n",
       " [763, 42, 414, 2482, 718, 23697],\n",
       " [11852, 7078, 15627, 9624, 0, 0],\n",
       " [1170, 5627, 1898, 642, 0, 0],\n",
       " [2, 480, 23698, 2900, 23699, 0],\n",
       " [3259, 882, 15628, 0, 0, 0],\n",
       " [70, 311, 15629, 5113, 4670, 0],\n",
       " [59, 28, 23700, 101, 23701, 0],\n",
       " [784, 23702, 5114, 0, 0, 0],\n",
       " [2075, 2274, 0, 0, 0, 0],\n",
       " [471, 1044, 0, 0, 0, 0],\n",
       " [17, 63, 142, 296, 4320, 29],\n",
       " [113, 106, 201, 11853, 0, 0],\n",
       " [8172, 1575, 8173, 9625, 465, 0],\n",
       " [23703, 23704, 6268, 0, 0, 0],\n",
       " [31, 4671, 1141, 0, 0, 0],\n",
       " [23705, 613, 9626, 117, 0, 0],\n",
       " [11854, 341, 23706, 296, 23707, 152],\n",
       " [5116, 2, 15630, 0, 0, 0],\n",
       " [2901, 181, 216, 9627, 1988, 15631],\n",
       " [23708, 1483, 11855, 0, 0, 0],\n",
       " [63, 3, 3731, 23709, 38, 0],\n",
       " [2483, 570, 0, 0, 0, 0],\n",
       " [464, 4, 380, 9629, 29, 23710],\n",
       " [66, 1205, 6270, 8174, 449, 0],\n",
       " [18, 2162, 0, 0, 0, 0],\n",
       " [275, 974, 11856, 11857, 0, 0],\n",
       " [9630, 1388, 34, 591, 102, 228],\n",
       " [11, 3486, 4001, 23712, 0, 0],\n",
       " [15632, 11858, 0, 0, 0, 0],\n",
       " [23713, 6271, 17, 0, 0, 0],\n",
       " [15633, 388, 830, 0, 0, 0],\n",
       " [27, 4673, 1989, 0, 0, 0],\n",
       " [90, 11859, 15634, 0, 0, 0],\n",
       " [2369, 1384, 0, 0, 0, 0],\n",
       " [158, 1142, 19, 20, 0, 0],\n",
       " [2754, 5628, 23714, 0, 0, 0],\n",
       " [234, 127, 210, 0, 0, 0],\n",
       " [109, 3064, 2755, 0, 0, 0],\n",
       " [66, 1533, 1236, 23715, 0, 0],\n",
       " [7, 23716, 0, 0, 0, 0],\n",
       " [7079, 339, 23717, 0, 0, 0],\n",
       " [11860, 4321, 107, 5629, 0, 0],\n",
       " [174, 233, 1139, 0, 0, 0],\n",
       " [2902, 1200, 744, 2903, 0, 0],\n",
       " [41, 3732, 0, 0, 0, 0],\n",
       " [7080, 311, 11861, 63, 25, 205],\n",
       " [143, 23718, 374, 745, 213, 181],\n",
       " [18, 59, 63, 1440, 1237, 74],\n",
       " [15635, 132, 107, 402, 0, 0],\n",
       " [1005, 1484, 23719, 0, 0, 0],\n",
       " [91, 11862, 1899, 0, 0, 0],\n",
       " [1695, 3065, 0, 0, 0, 0],\n",
       " [2756, 321, 23720, 4002, 0, 0],\n",
       " [23721, 11863, 2607, 0, 0, 0],\n",
       " [11864, 2275, 4009, 8176, 1441, 0],\n",
       " [15636, 46, 1900, 0, 0, 0],\n",
       " [614, 8, 5, 23722, 17, 120],\n",
       " [4674, 67, 2484, 3066, 0, 0],\n",
       " [341, 7, 23723, 0, 0, 0],\n",
       " [905, 970, 9631, 0, 0, 0],\n",
       " [11, 505, 1143, 0, 0, 0],\n",
       " [2077, 7081, 5630, 392, 0, 0],\n",
       " [342, 23724, 8177, 481, 392, 0],\n",
       " [1354, 23725, 0, 0, 0, 0],\n",
       " [851, 685, 2, 10, 5117, 0],\n",
       " [9, 199, 1750, 30, 22, 8178],\n",
       " [277, 139, 4010, 1238, 686, 0],\n",
       " [23726, 8179, 48, 8180, 0, 0],\n",
       " [1107, 5118, 0, 0, 0, 0],\n",
       " [1006, 2370, 1990, 2276, 977, 952],\n",
       " [1751, 34, 9632, 0, 0, 0],\n",
       " [3067, 8, 5631, 23727, 1048, 0],\n",
       " [567, 8182, 0, 0, 0, 0],\n",
       " [26, 23728, 2485, 32, 2748, 0],\n",
       " [224, 302, 325, 415, 29, 113],\n",
       " [35, 190, 77, 9633, 0, 0],\n",
       " [23, 851, 685, 0, 0, 0],\n",
       " [15637, 1206, 0, 0, 0, 0],\n",
       " [5632, 328, 2486, 1634, 25, 0],\n",
       " [32, 8183, 11865, 9, 461, 23729],\n",
       " [1576, 1485, 230, 183, 282, 0],\n",
       " [5633, 42, 699, 0, 0, 0],\n",
       " [700, 4012, 104, 0, 0, 0],\n",
       " [218, 15638, 82, 442, 0, 0],\n",
       " [3260, 5634, 1108, 0, 0, 0],\n",
       " [23730, 76, 11866, 0, 0, 0],\n",
       " [23731, 15639, 11867, 0, 0, 0],\n",
       " [15640, 4322, 28, 15641, 9634, 0],\n",
       " [4675, 659, 23732, 747, 101, 15642],\n",
       " [23733, 112, 79, 0, 0, 0],\n",
       " [1692, 15643, 409, 4676, 0, 0],\n",
       " [119, 1109, 2277, 1144, 812, 0],\n",
       " [431, 148, 1688, 9, 975, 19],\n",
       " [764, 15644, 60, 862, 96, 130],\n",
       " [23734, 9635, 1752, 0, 0, 0],\n",
       " [5635, 458, 0, 0, 0, 0],\n",
       " [813, 7082, 268, 28, 153, 744],\n",
       " [414, 37, 1991, 55, 135, 23735],\n",
       " [380, 23736, 0, 0, 0, 0],\n",
       " [488, 11, 2262, 15645, 0, 0],\n",
       " [1572, 23737, 1691, 23738, 23739, 2278],\n",
       " [3261, 1310, 15646, 23741, 0, 0],\n",
       " [1816, 58, 14, 9, 15647, 11868],\n",
       " [9594, 1577, 29, 3068, 0, 0],\n",
       " [340, 1389, 0, 0, 0, 0],\n",
       " [476, 2279, 278, 23742, 0, 0],\n",
       " [67, 588, 4323, 45, 1534, 23743],\n",
       " [397, 15648, 1696, 0, 0, 0],\n",
       " [11, 23744, 9636, 23745, 0, 0],\n",
       " [23746, 23747, 43, 5636, 334, 149],\n",
       " [642, 1269, 105, 592, 29, 4324],\n",
       " [748, 749, 23748, 0, 0, 0],\n",
       " [2757, 9637, 1269, 2904, 0, 0],\n",
       " [6272, 2758, 11869, 278, 615, 0],\n",
       " [74, 497, 1049, 3069, 178, 3],\n",
       " [23749, 5637, 133, 0, 0, 0],\n",
       " [1171, 2, 3477, 15649, 15650, 1231],\n",
       " [312, 634, 23750, 0, 0, 0],\n",
       " [59, 6, 3487, 158, 3487, 1901],\n",
       " [9638, 8184, 84, 2608, 4013, 0],\n",
       " [200, 8, 1145, 54, 38, 0],\n",
       " [23751, 4325, 23752, 0, 0, 0],\n",
       " [9639, 23753, 0, 0, 0, 0],\n",
       " [469, 1235, 39, 71, 2905, 0],\n",
       " [7083, 1390, 23754, 0, 0, 0],\n",
       " [62, 50, 2078, 23755, 0, 0],\n",
       " [45, 9640, 15651, 0, 0, 0],\n",
       " [23756, 9641, 0, 0, 0, 0],\n",
       " [2906, 23757, 0, 0, 0, 0],\n",
       " [18, 127, 403, 6273, 1992, 0],\n",
       " [11870, 44, 0, 0, 0, 0],\n",
       " [1578, 340, 23758, 0, 0, 0],\n",
       " [884, 1235, 550, 3733, 473, 0],\n",
       " [23759, 7, 451, 800, 0, 0],\n",
       " [23760, 5638, 15652, 0, 0, 0],\n",
       " [23761, 3734, 537, 56, 109, 0],\n",
       " [72, 997, 6274, 0, 0, 0],\n",
       " [3070, 11871, 0, 0, 0, 0],\n",
       " [1110, 532, 15653, 4014, 7084, 0],\n",
       " [15654, 324, 84, 5119, 2907, 34],\n",
       " [206, 2163, 26, 11872, 0, 0],\n",
       " [11873, 5120, 79, 216, 0, 0],\n",
       " [361, 15655, 1635, 12, 285, 0],\n",
       " [9, 1438, 11874, 0, 0, 0],\n",
       " [5639, 2487, 0, 0, 0, 0],\n",
       " [6275, 571, 0, 0, 0, 0],\n",
       " [1900, 3262, 7086, 0, 0, 0],\n",
       " [32, 23762, 10, 3488, 8185, 0],\n",
       " [1197, 9642, 9643, 0, 0, 0],\n",
       " [189, 885, 11875, 765, 11876, 0],\n",
       " [1050, 1486, 6276, 0, 0, 0],\n",
       " [23763, 0, 0, 0, 0, 0],\n",
       " [23764, 56, 1993, 0, 0, 0],\n",
       " [34, 23765, 0, 0, 0, 0],\n",
       " [23766, 8186, 333, 0, 0, 0],\n",
       " [232, 367, 1994, 0, 0, 0],\n",
       " [448, 517, 92, 863, 0, 0],\n",
       " [23767, 23768, 23769, 0, 0, 0],\n",
       " [2363, 23770, 0, 0, 0, 0],\n",
       " [38, 8, 54, 86, 1207, 0],\n",
       " [6243, 170, 101, 23771, 3071, 0],\n",
       " [15656, 132, 730, 8187, 7, 451],\n",
       " [2488, 7087, 120, 0, 0, 0],\n",
       " [1636, 15657, 23772, 697, 84, 3072],\n",
       " [66, 51, 1311, 17, 347, 9644],\n",
       " [191, 11878, 34, 2164, 4677, 0],\n",
       " [766, 2165, 92, 2908, 101, 23773],\n",
       " [256, 1111, 23774, 23775, 0, 0],\n",
       " [47, 1007, 23776, 23777, 0, 0],\n",
       " [15658, 23778, 5121, 668, 0, 0],\n",
       " [1753, 1752, 572, 4678, 80, 0],\n",
       " [18, 132, 11879, 7088, 0, 0],\n",
       " [9645, 1008, 3073, 9646, 0, 0],\n",
       " [62, 7, 3263, 9647, 498, 2609],\n",
       " [3735, 2, 103, 9648, 0, 0],\n",
       " [2280, 8190, 2759, 0, 0, 0],\n",
       " [172, 11880, 33, 719, 5640, 0],\n",
       " [23779, 538, 9649, 9650, 0, 0],\n",
       " [145, 294, 6277, 4326, 3736, 5122],\n",
       " [1442, 23780, 0, 0, 0, 0],\n",
       " [2371, 1637, 0, 0, 0, 0],\n",
       " [23781, 2, 5641, 79, 4679, 0],\n",
       " [815, 11881, 4327, 0, 0, 0],\n",
       " [1754, 462, 23782, 162, 85, 1443],\n",
       " [23783, 6278, 0, 0, 0, 0],\n",
       " [3489, 335, 432, 4328, 4680, 0],\n",
       " [1391, 573, 4681, 8191, 750, 0],\n",
       " [524, 34, 667, 0, 0, 0],\n",
       " [1817, 9651, 1, 0, 0, 0],\n",
       " [163, 15659, 0, 0, 0, 0],\n",
       " [284, 1902, 23784, 0, 0, 0],\n",
       " [23785, 15660, 0, 0, 0, 0],\n",
       " [32, 23786, 0, 0, 0, 0],\n",
       " [797, 9652, 23787, 53, 1579, 2372],\n",
       " [1697, 303, 518, 2079, 536, 0],\n",
       " [578, 16, 133, 886, 387, 0],\n",
       " [2489, 23788, 767, 2166, 15661, 0],\n",
       " [905, 1970, 134, 4682, 0, 0],\n",
       " [8192, 15662, 146, 0, 0, 0],\n",
       " [11, 4329, 15663, 0, 0, 0],\n",
       " [52, 15664, 23789, 2281, 669, 0],\n",
       " [4015, 8193, 15665, 3737, 0, 0],\n",
       " [15666, 1049, 0, 0, 0, 0],\n",
       " [8194, 751, 499, 1487, 4330, 0],\n",
       " [9653, 23790, 1051, 0, 0, 0],\n",
       " [797, 80, 1, 34, 97, 0],\n",
       " [422, 2490, 118, 6279, 248, 0],\n",
       " [1638, 4331, 7, 463, 5123, 951],\n",
       " [4321, 602, 30, 284, 3074, 0],\n",
       " [23791, 9654, 0, 0, 0, 0],\n",
       " [11882, 58, 3738, 441, 9, 3264],\n",
       " [23792, 410, 1755, 1444, 0, 0],\n",
       " [433, 109, 1635, 12, 59, 686],\n",
       " [24, 118, 2760, 7089, 37, 37],\n",
       " [23793, 7090, 0, 0, 0, 0],\n",
       " [23794, 1312, 11883, 5124, 0, 0],\n",
       " [51, 5642, 1580, 0, 0, 0],\n",
       " [8, 7091, 23795, 101, 1445, 446],\n",
       " [470, 600, 114, 658, 7, 6280],\n",
       " [798, 831, 701, 7092, 434, 332],\n",
       " [768, 5125, 67, 1052, 0, 0],\n",
       " [6, 8195, 23796, 23797, 0, 0],\n",
       " [393, 159, 15667, 0, 0, 0],\n",
       " [1072, 65, 16, 2167, 41, 0],\n",
       " [381, 301, 735, 0, 0, 0],\n",
       " [1488, 1756, 2080, 801, 6281, 702],\n",
       " [11884, 23798, 15668, 38, 0, 0],\n",
       " [1698, 8, 2611, 362, 44, 0],\n",
       " [6282, 9, 7093, 11885, 0, 0],\n",
       " [491, 23799, 0, 0, 0, 0],\n",
       " [1524, 218, 23800, 388, 0, 0],\n",
       " [23801, 2612, 3266, 7094, 0, 0],\n",
       " [15669, 7095, 7096, 23802, 15670, 1208],\n",
       " [23803, 429, 0, 0, 0, 0],\n",
       " [23804, 559, 15671, 0, 0, 0],\n",
       " [5643, 2071, 528, 2265, 1392, 343],\n",
       " [1146, 15672, 4333, 15673, 3075, 816],\n",
       " [32, 6283, 9, 6284, 4683, 2168],\n",
       " [36, 245, 2761, 2491, 687, 11886],\n",
       " [23805, 46, 9655, 5, 126, 3242],\n",
       " [3267, 8196, 0, 0, 0, 0],\n",
       " [8197, 500, 2613, 23806, 5644, 0],\n",
       " [5, 1757, 766, 12, 22, 339],\n",
       " [110, 4016, 23807, 0, 0, 0],\n",
       " [9656, 2282, 23808, 1818, 0, 0],\n",
       " [8198, 15674, 46, 0, 0, 0],\n",
       " [4684, 4334, 0, 0, 0, 0],\n",
       " [15675, 313, 6285, 19, 107, 313],\n",
       " [11887, 91, 9657, 393, 23, 0],\n",
       " [688, 8199, 9658, 23809, 0, 0],\n",
       " [1313, 4685, 88, 0, 0, 0],\n",
       " [192, 100, 23810, 949, 1112, 3076],\n",
       " [2169, 3064, 23811, 1209, 0, 0],\n",
       " [7097, 4017, 382, 164, 15676, 451],\n",
       " [23812, 1903, 1903, 0, 0, 0],\n",
       " [23813, 23814, 0, 0, 0, 0],\n",
       " [579, 23815, 5126, 0, 0, 0],\n",
       " [4335, 4686, 4687, 30, 717, 0],\n",
       " [3490, 23816, 9659, 0, 0, 0],\n",
       " [1746, 23817, 2, 23818, 23819, 0],\n",
       " [4336, 5127, 0, 0, 0, 0],\n",
       " [1527, 23820, 23821, 0, 0, 0],\n",
       " [269, 5645, 434, 2, 2170, 12],\n",
       " [2614, 199, 15677, 4337, 0, 0],\n",
       " [262, 4329, 4688, 23822, 4689, 0],\n",
       " [87, 4018, 1113, 4338, 571, 0],\n",
       " [8, 3739, 1758, 0, 0, 0],\n",
       " [15678, 580, 6286, 0, 0, 0],\n",
       " [929, 2762, 1489, 3268, 2072, 0],\n",
       " [3077, 81, 670, 1079, 0, 0],\n",
       " [3078, 3740, 3491, 1, 0, 0],\n",
       " [736, 37, 0, 0, 0, 0],\n",
       " [3079, 11888, 1819, 15679, 0, 0],\n",
       " [8201, 15680, 0, 0, 0, 0],\n",
       " [9, 2081, 147, 1314, 0, 0],\n",
       " [1200, 2171, 2082, 227, 5128, 258],\n",
       " [53, 632, 350, 23823, 0, 0],\n",
       " [11, 635, 3741, 23824, 0, 0],\n",
       " [23825, 26, 23826, 32, 8202, 0],\n",
       " [11, 23827, 1207, 11889, 257, 11890],\n",
       " [365, 3269, 2172, 1, 0, 0],\n",
       " [1304, 23828, 4648, 331, 0, 0],\n",
       " [23829, 593, 1699, 0, 0, 0],\n",
       " [206, 1210, 23830, 832, 1535, 0],\n",
       " [2083, 8203, 23831, 2, 23832, 0],\n",
       " [45, 23833, 1143, 0, 0, 0],\n",
       " [6287, 9660, 0, 0, 0, 0],\n",
       " [461, 8204, 23834, 0, 0, 0],\n",
       " [2615, 9661, 7, 5129, 0, 0],\n",
       " [15681, 4690, 516, 3080, 581, 9662],\n",
       " [144, 6288, 0, 0, 0, 0],\n",
       " [238, 15682, 6289, 930, 65, 904],\n",
       " [23836, 737, 715, 263, 0, 0],\n",
       " [1355, 696, 1631, 4653, 217, 282],\n",
       " [112, 23837, 0, 0, 0, 0],\n",
       " [365, 478, 7098, 332, 0, 0],\n",
       " [23838, 268, 28, 190, 4018, 0],\n",
       " [15683, 1, 260, 0, 0, 0],\n",
       " [2068, 9663, 1888, 23839, 15684, 416],\n",
       " [1239, 557, 582, 0, 0, 0],\n",
       " [433, 2174, 31, 0, 0, 0],\n",
       " [15685, 23843, 0, 0, 0, 0],\n",
       " [62, 21, 9665, 0, 0, 0],\n",
       " [23844, 343, 20, 972, 0, 0],\n",
       " [398, 5130, 22, 414, 0, 0],\n",
       " [9666, 3, 0, 0, 0, 0],\n",
       " [1446, 603, 174, 348, 0, 0],\n",
       " [11891, 33, 15686, 17, 2755, 0],\n",
       " [5131, 451, 3492, 346, 4019, 3270],\n",
       " [23845, 23846, 0, 0, 0, 0],\n",
       " [11892, 23847, 0, 0, 0, 0],\n",
       " [1572, 15687, 0, 0, 0, 0],\n",
       " [34, 11893, 525, 0, 0, 0],\n",
       " [11894, 1240, 0, 0, 0, 0],\n",
       " [23848, 5, 646, 1820, 23849, 0],\n",
       " [18, 73, 671, 15688, 15689, 0],\n",
       " [906, 1, 23850, 121, 0, 0],\n",
       " [15690, 125, 4692, 31, 5646, 3493],\n",
       " [23851, 80, 0, 0, 0, 0],\n",
       " [5647, 433, 224, 263, 1981, 2492],\n",
       " [487, 8205, 23852, 476, 0, 0],\n",
       " [1759, 5648, 319, 9667, 1009, 15691],\n",
       " [369, 2, 5132, 448, 0, 0],\n",
       " [59, 4693, 23853, 23854, 0, 0],\n",
       " [23855, 4020, 15692, 537, 15693, 8206],\n",
       " [1995, 5133, 3271, 3494, 15694, 117],\n",
       " [122, 23856, 28, 0, 0, 0],\n",
       " [9668, 0, 0, 0, 0, 0],\n",
       " [15695, 166, 0, 0, 0, 0],\n",
       " [11895, 8207, 8208, 0, 0, 0],\n",
       " [23857, 5649, 0, 0, 0, 0],\n",
       " [888, 888, 734, 0, 0, 0],\n",
       " [363, 5134, 526, 30, 0, 0],\n",
       " [1355, 9, 436, 23858, 23859, 0],\n",
       " [174, 8209, 409, 36, 625, 0],\n",
       " [6290, 60, 23860, 931, 0, 0],\n",
       " [470, 181, 1581, 3742, 194, 23861],\n",
       " [681, 734, 2763, 0, 0, 0],\n",
       " [66, 23862, 23863, 0, 0, 0],\n",
       " [3495, 23864, 0, 0, 0, 0],\n",
       " [3272, 23865, 0, 0, 0, 0],\n",
       " [76, 23866, 7, 1315, 1, 0],\n",
       " [5134, 6291, 9669, 0, 0, 0],\n",
       " [59, 852, 864, 0, 0, 0],\n",
       " [1073, 324, 1010, 0, 0, 0],\n",
       " [2764, 23867, 195, 570, 15, 13],\n",
       " [11896, 361, 1048, 1639, 0, 0],\n",
       " [11897, 452, 387, 311, 15696, 19],\n",
       " [23868, 478, 2765, 249, 263, 0],\n",
       " [8, 4021, 6, 313, 5650, 2283],\n",
       " [120, 2175, 797, 23869, 0, 0],\n",
       " [3273, 4022, 853, 0, 0, 0],\n",
       " [5, 785, 23870, 0, 0, 0],\n",
       " [559, 23871, 0, 0, 0, 0],\n",
       " [1904, 604, 225, 11898, 0, 0],\n",
       " [40, 7099, 0, 0, 0, 0],\n",
       " [18, 1822, 2616, 0, 0, 0],\n",
       " [4, 11899, 1760, 2617, 0, 0],\n",
       " [339, 1761, 1011, 769, 0, 0],\n",
       " [6292, 23872, 23873, 1, 23874, 0],\n",
       " [4297, 23875, 41, 0, 0, 0],\n",
       " [4694, 485, 616, 165, 23876, 22],\n",
       " [1996, 23877, 0, 0, 0, 0],\n",
       " [35, 7, 1273, 0, 0, 0],\n",
       " [9671, 2766, 0, 0, 0, 0],\n",
       " [6293, 15697, 214, 6294, 0, 0],\n",
       " [23878, 3081, 23879, 0, 0, 0],\n",
       " [2176, 8211, 192, 0, 0, 0],\n",
       " [1241, 2177, 15698, 0, 0, 0],\n",
       " [9672, 2, 7, 5135, 4023, 1447],\n",
       " [2767, 15699, 4340, 817, 0, 0],\n",
       " [888, 262, 15700, 0, 0, 0],\n",
       " [11901, 1316, 5136, 97, 9673, 2284],\n",
       " [287, 8212, 1762, 23880, 0, 0],\n",
       " [770, 6295, 8213, 0, 0, 0],\n",
       " [3068, 2374, 86, 20, 0, 0],\n",
       " [15701, 9, 77, 0, 0, 0],\n",
       " [21, 414, 108, 0, 0, 0],\n",
       " [1356, 3743, 11902, 23881, 73, 23882],\n",
       " [34, 9, 317, 3496, 953, 0],\n",
       " [9674, 23883, 7100, 3744, 182, 0],\n",
       " [157, 2375, 111, 0, 0, 0],\n",
       " [5, 355, 250, 1242, 109, 15702],\n",
       " [344, 3497, 405, 14, 560, 0],\n",
       " [1640, 2768, 15703, 7101, 0, 0],\n",
       " [57, 23884, 1, 802, 10, 1053],\n",
       " [378, 11903, 5651, 0, 0, 0],\n",
       " [108, 752, 11904, 46, 5137, 0],\n",
       " [689, 3263, 322, 23885, 23886, 0],\n",
       " [519, 15704, 0, 0, 0, 0],\n",
       " [505, 567, 6296, 7102, 0, 0],\n",
       " [15705, 23887, 4695, 0, 0, 0],\n",
       " [1700, 23888, 297, 0, 0, 0],\n",
       " [3082, 763, 5, 401, 0, 0],\n",
       " [29, 6, 61, 15706, 0, 0],\n",
       " [394, 307, 7103, 6297, 1147, 0],\n",
       " [23889, 56, 2618, 469, 23890, 0],\n",
       " [23891, 15707, 15708, 9, 785, 2376],\n",
       " [130, 3739, 2769, 23892, 23893, 329],\n",
       " [1012, 145, 9675, 4, 3274, 0],\n",
       " [23895, 5, 4696, 23896, 0, 0],\n",
       " [8214, 2168, 524, 383, 458, 15709],\n",
       " [9676, 55, 4341, 123, 3, 0],\n",
       " [3745, 382, 1905, 23897, 0, 0],\n",
       " [24, 288, 907, 908, 23898, 0],\n",
       " [499, 97, 23899, 0, 0, 0],\n",
       " [23900, 4024, 0, 0, 0, 0],\n",
       " [7104, 7105, 583, 443, 0, 0],\n",
       " [2619, 334, 15710, 1141, 0, 0],\n",
       " [23901, 908, 1690, 8215, 0, 0],\n",
       " [908, 33, 818, 12, 1240, 23902],\n",
       " [10, 9677, 118, 0, 0, 0],\n",
       " [1641, 9678, 52, 122, 1442, 5652],\n",
       " [23903, 42, 18, 403, 0, 0],\n",
       " [23904, 6298, 0, 0, 0, 0],\n",
       " [23905, 121, 0, 0, 0, 0],\n",
       " [3083, 499, 1642, 11905, 0, 0],\n",
       " [23906, 1760, 11906, 7, 751, 0],\n",
       " [126, 23907, 15711, 23908, 0, 0],\n",
       " [2178, 829, 0, 0, 0, 0],\n",
       " [2, 5138, 731, 1013, 9583, 2377],\n",
       " [8216, 5653, 23909, 0, 0, 0],\n",
       " [2770, 23910, 23911, 0, 0, 0],\n",
       " [786, 4697, 48, 4, 181, 932],\n",
       " [1998, 11907, 21, 4699, 0, 0],\n",
       " [15713, 1014, 23912, 0, 0, 0],\n",
       " [787, 5139, 0, 0, 0, 0],\n",
       " [256, 3746, 8218, 695, 4326, 20],\n",
       " [1, 474, 475, 0, 0, 0],\n",
       " [7106, 23913, 86, 287, 0, 0],\n",
       " [6300, 11908, 2179, 15714, 0, 0],\n",
       " [5140, 4, 15715, 9679, 568, 0],\n",
       " [23914, 215, 3498, 1394, 1973, 23915],\n",
       " [3499, 3747, 8219, 4019, 0, 0],\n",
       " [163, 23916, 23917, 0, 0, 0],\n",
       " [139, 109, 5654, 4026, 0, 0],\n",
       " [96, 11909, 7, 167, 3084, 0],\n",
       " [8220, 4008, 2620, 1448, 0, 0],\n",
       " [23918, 23919, 662, 568, 0, 0],\n",
       " [154, 5141, 1270, 344, 1906, 18],\n",
       " [720, 3275, 0, 0, 0, 0],\n",
       " [909, 8221, 5655, 0, 0, 0],\n",
       " [536, 3748, 26, 4700, 11910, 0],\n",
       " [2493, 1317, 157, 8222, 254, 10],\n",
       " [2374, 3085, 28, 458, 7107, 23920],\n",
       " [2084, 123, 30, 22, 3500, 11911],\n",
       " [11912, 111, 90, 98, 23921, 5656],\n",
       " [8223, 4027, 0, 0, 0, 0],\n",
       " [75, 83, 23922, 558, 23923, 0],\n",
       " [140, 3276, 20, 0, 0, 0],\n",
       " [737, 539, 625, 282, 0, 0],\n",
       " [15716, 437, 23924, 0, 0, 0],\n",
       " [1999, 886, 647, 0, 0, 0],\n",
       " [597, 12, 762, 1357, 3, 0],\n",
       " [1311, 139, 9, 79, 25, 0],\n",
       " [23925, 11913, 2154, 0, 0, 0],\n",
       " [648, 1643, 6301, 0, 0, 0],\n",
       " [1582, 765, 9680, 0, 0, 0],\n",
       " [15717, 2747, 8224, 23926, 0, 0],\n",
       " [344, 11, 8225, 4658, 11, 1449],\n",
       " [3749, 9681, 1006, 319, 2285, 833],\n",
       " [1391, 42, 9682, 0, 0, 0],\n",
       " [1391, 23927, 0, 0, 0, 0],\n",
       " [3086, 8226, 2771, 0, 0, 0],\n",
       " [365, 15719, 11914, 23928, 7108, 0],\n",
       " [753, 796, 5643, 0, 0, 0],\n",
       " [18, 11915, 702, 23929, 0, 0],\n",
       " [285, 2621, 1763, 3, 241, 3501],\n",
       " [15720, 341, 23930, 2379, 7109, 4342],\n",
       " [15721, 704, 2622, 1749, 0, 0],\n",
       " [63, 180, 23931, 427, 0, 0],\n",
       " [7110, 1764, 205, 631, 0, 0],\n",
       " [174, 348, 1172, 2772, 0, 0],\n",
       " [4343, 15722, 192, 0, 0, 0],\n",
       " [23932, 239, 95, 0, 0, 0],\n",
       " [23933, 278, 23934, 0, 0, 0],\n",
       " [282, 2898, 1274, 3, 5142, 1274],\n",
       " [1211, 10, 2773, 0, 0, 0],\n",
       " [23935, 1765, 20, 0, 0, 0],\n",
       " [466, 5143, 274, 0, 0, 0],\n",
       " [23936, 23937, 834, 57, 3277, 7111],\n",
       " [207, 306, 56, 102, 1536, 0],\n",
       " [9, 23938, 8227, 0, 0, 0],\n",
       " [1173, 10, 15723, 0, 0, 0],\n",
       " [75, 1583, 23939, 0, 0, 0],\n",
       " [23940, 16, 162, 3, 77, 0],\n",
       " [11916, 0, 0, 0, 0, 0],\n",
       " [1972, 105, 68, 482, 1584, 0],\n",
       " [10, 5657, 1, 260, 0, 0],\n",
       " [472, 482, 67, 139, 180, 6303],\n",
       " [3278, 45, 1, 388, 0, 0],\n",
       " [131, 4018, 23941, 4344, 0, 0],\n",
       " [1015, 885, 8228, 0, 0, 0],\n",
       " [744, 4297, 34, 1894, 205, 3279],\n",
       " [23942, 23943, 2774, 15724, 0, 0],\n",
       " [6, 105, 68, 584, 865, 0],\n",
       " [284, 4345, 304, 1902, 157, 0],\n",
       " [321, 4704, 362, 15725, 6, 180],\n",
       " [88, 24, 1907, 574, 232, 422],\n",
       " [9683, 8229, 0, 0, 0, 0],\n",
       " [4, 559, 2909, 0, 0, 0],\n",
       " [3088, 278, 11917, 0, 0, 0],\n",
       " [6305, 526, 3, 0, 0, 0],\n",
       " [2623, 2910, 1, 124, 1823, 0],\n",
       " [23944, 166, 3750, 23945, 0, 0],\n",
       " [23946, 1908, 23947, 0, 0, 0],\n",
       " [56, 23948, 0, 0, 0, 0],\n",
       " [23949, 4705, 457, 2476, 1318, 0],\n",
       " [9684, 5658, 0, 0, 0, 0],\n",
       " [145, 23950, 0, 0, 0, 0],\n",
       " [82, 428, 23951, 1450, 0, 0],\n",
       " [362, 15726, 0, 0, 0, 0],\n",
       " [145, 11918, 2000, 0, 0, 0],\n",
       " [1391, 1395, 4, 23952, 0, 0],\n",
       " [3751, 105, 550, 0, 0, 0],\n",
       " [1909, 69, 411, 389, 305, 11919],\n",
       " [179, 217, 303, 2162, 3, 866],\n",
       " [23953, 6306, 3089, 361, 40, 3090],\n",
       " [23955, 1319, 803, 182, 0, 0],\n",
       " [1582, 268, 62, 83, 11920, 3091],\n",
       " [277, 2494, 68, 301, 8230, 0],\n",
       " [250, 333, 1451, 11921, 0, 0],\n",
       " [15727, 4346, 3502, 0, 0, 0],\n",
       " [765, 99, 23957, 0, 0, 0],\n",
       " [43, 11922, 4028, 0, 0, 0],\n",
       " [1824, 23958, 2085, 0, 0, 0],\n",
       " [23959, 158, 933, 0, 0, 0],\n",
       " [2181, 604, 4706, 0, 0, 0],\n",
       " [1016, 6307, 1910, 1212, 6, 23960],\n",
       " [24, 9685, 214, 86, 3752, 0],\n",
       " [387, 5659, 112, 153, 0, 0],\n",
       " [485, 1237, 3092, 12, 22, 0],\n",
       " [431, 930, 1766, 1320, 1275, 0],\n",
       " [7112, 3093, 5, 7113, 3503, 0],\n",
       " [11923, 33, 36, 373, 22, 23961],\n",
       " [3997, 96, 113, 3, 2495, 0],\n",
       " [154, 23962, 214, 5660, 3089, 0],\n",
       " [4708, 501, 23963, 5661, 1644, 0],\n",
       " [89, 192, 1638, 23964, 0, 0],\n",
       " [9686, 1893, 23965, 0, 0, 0],\n",
       " [74, 11924, 11925, 42, 231, 2775],\n",
       " [90, 2086, 118, 1992, 0, 0],\n",
       " [15728, 370, 147, 0, 0, 0],\n",
       " [23966, 736, 0, 0, 0, 0],\n",
       " [9687, 98, 4029, 1053, 0, 0],\n",
       " [325, 551, 110, 7114, 473, 0],\n",
       " [5, 15729, 23967, 0, 0, 0],\n",
       " [155, 3753, 23968, 4347, 329, 15730],\n",
       " [1911, 380, 15731, 394, 1764, 6308],\n",
       " [23970, 94, 64, 414, 8231, 23971],\n",
       " [35, 158, 6, 7092, 44, 197],\n",
       " [156, 549, 63, 705, 864, 20],\n",
       " [314, 4030, 3754, 735, 788, 0],\n",
       " [2911, 23973, 0, 0, 0, 0],\n",
       " [5662, 315, 2087, 0, 0, 0],\n",
       " [23974, 3094, 0, 0, 0, 0],\n",
       " [8232, 15732, 23975, 0, 0, 0],\n",
       " [15733, 7115, 0, 0, 0, 0],\n",
       " [34, 1486, 126, 310, 0, 0],\n",
       " [7116, 8233, 75, 1175, 2182, 0],\n",
       " [978, 196, 0, 0, 0, 0],\n",
       " [23976, 578, 164, 0, 0, 0],\n",
       " [2165, 9688, 59, 23977, 0, 0],\n",
       " [4031, 1005, 1767, 15734, 0, 0],\n",
       " [23978, 23, 1045, 4681, 5663, 23979],\n",
       " [348, 1213, 11926, 0, 0, 0],\n",
       " [23980, 241, 1321, 8234, 5664, 0],\n",
       " [48, 634, 8235, 23981, 0, 0],\n",
       " [289, 23982, 1358, 11927, 9689, 15735],\n",
       " [23983, 91, 1017, 2183, 0, 0],\n",
       " [259, 5665, 528, 19, 2767, 15736],\n",
       " [33, 4032, 5144, 15737, 1054, 260],\n",
       " [614, 8, 71, 706, 1748, 0],\n",
       " [1239, 107, 6307, 74, 377, 24],\n",
       " [4033, 4348, 0, 0, 0, 0],\n",
       " [23984, 835, 2624, 0, 0, 0],\n",
       " [1055, 15738, 0, 0, 0, 0],\n",
       " [8, 15739, 10, 158, 11928, 0],\n",
       " [1645, 145, 23985, 0, 0, 0],\n",
       " [50, 25, 7117, 92, 3, 529],\n",
       " [35, 137, 2625, 23986, 0, 0],\n",
       " [23987, 2088, 0, 0, 0, 0],\n",
       " [11929, 2, 5666, 1825, 0, 0],\n",
       " [357, 6309, 1236, 0, 0, 0],\n",
       " [15740, 9690, 8236, 0, 0, 0],\n",
       " [1396, 4709, 323, 0, 0, 0],\n",
       " [23988, 1769, 0, 0, 0, 0],\n",
       " [216, 9691, 11930, 0, 0, 0],\n",
       " [707, 295, 2381, 1646, 0, 0],\n",
       " [2626, 23989, 492, 0, 0, 0],\n",
       " [681, 2776, 0, 0, 0, 0],\n",
       " [786, 167, 2089, 2090, 114, 2001],\n",
       " [23990, 23991, 0, 0, 0, 0],\n",
       " [6, 158, 867, 8237, 0, 0],\n",
       " [112, 2912, 789, 0, 0, 0],\n",
       " [23992, 8238, 0, 0, 0, 0],\n",
       " [11, 11931, 23993, 354, 1397, 707],\n",
       " [1701, 11932, 7118, 1770, 4035, 3504],\n",
       " [66, 88, 1080, 3505, 0, 0],\n",
       " [9692, 69, 2777, 12, 0, 0],\n",
       " [5667, 3755, 344, 15741, 23994, 0],\n",
       " [979, 27, 687, 0, 0, 0],\n",
       " [2184, 15742, 1912, 1585, 0, 0],\n",
       " [1243, 1275, 0, 0, 0, 0],\n",
       " [1202, 8239, 2748, 0, 0, 0],\n",
       " [2286, 11933, 23, 0, 0, 0],\n",
       " [980, 6310, 1398, 23995, 8240, 0],\n",
       " [649, 2002, 23996, 1399, 2496, 0],\n",
       " [605, 14, 6311, 0, 0, 0],\n",
       " [1771, 6312, 3756, 25, 518, 1],\n",
       " [8, 1767, 128, 6313, 0, 0],\n",
       " [4349, 4663, 5, 11934, 0, 0],\n",
       " [109, 666, 98, 1011, 0, 0],\n",
       " [7119, 47, 2913, 236, 2905, 0],\n",
       " [52, 9601, 5, 716, 2181, 0],\n",
       " [23997, 23998, 2169, 3065, 5145, 0],\n",
       " [1205, 15743, 86, 0, 0, 0],\n",
       " [4350, 7120, 23999, 5668, 3280, 0],\n",
       " [671, 15744, 2003, 0, 0, 0],\n",
       " [930, 268, 24000, 5669, 0, 0],\n",
       " [397, 1826, 9, 461, 588, 15745],\n",
       " [15746, 4352, 3281, 0, 0, 0],\n",
       " [24001, 348, 24002, 0, 0, 0],\n",
       " [3282, 1176, 15747, 0, 0, 0],\n",
       " [7121, 7122, 0, 0, 0, 0],\n",
       " [73, 904, 91, 0, 0, 0],\n",
       " [228, 25, 2778, 2914, 0, 0],\n",
       " [3757, 604, 11935, 11850, 0, 0],\n",
       " [9, 199, 139, 30, 22, 5146],\n",
       " [700, 4036, 104, 0, 0, 0],\n",
       " [17, 217, 771, 3095, 205, 24004],\n",
       " [4321, 36, 625, 0, 0, 0],\n",
       " [58, 11936, 255, 7, 6314, 0],\n",
       " [24005, 24006, 15748, 0, 0, 0],\n",
       " [24007, 48, 672, 0, 0, 0],\n",
       " [1322, 67, 588, 24008, 24009, 0],\n",
       " [1359, 6315, 1244, 0, 0, 0],\n",
       " [882, 524, 8241, 9693, 0, 0],\n",
       " [24010, 3506, 0, 0, 0, 0],\n",
       " [1214, 132, 1109, 24011, 0, 0],\n",
       " [24012, 423, 1895, 6316, 0, 0],\n",
       " [1109, 1103, 24013, 209, 15749, 0],\n",
       " [24014, 0, 0, 0, 0, 0],\n",
       " [5670, 268, 24015, 129, 0, 0],\n",
       " [8, 2916, 209, 2262, 0, 0],\n",
       " [172, 24016, 5, 401, 11937, 291],\n",
       " [3758, 903, 5147, 24017, 0, 0],\n",
       " [1702, 74, 9, 80, 0, 0],\n",
       " [15750, 24018, 0, 0, 0, 0],\n",
       " [5671, 1987, 0, 0, 0, 0],\n",
       " [2287, 24019, 0, 0, 0, 0],\n",
       " [35, 24020, 2776, 0, 0, 0],\n",
       " [1647, 111, 2477, 1275, 0, 0],\n",
       " [228, 1177, 3480, 681, 0, 0],\n",
       " [3283, 24021, 9694, 0, 0, 0],\n",
       " [9695, 9632, 0, 0, 0, 0],\n",
       " [11938, 437, 650, 0, 0, 0],\n",
       " [24022, 17, 15751, 754, 0, 0],\n",
       " [10, 11939, 25, 687, 0, 0],\n",
       " [275, 24023, 5672, 4693, 15752, 0],\n",
       " [8242, 5148, 122, 498, 487, 8243],\n",
       " [8244, 428, 9, 248, 0, 0],\n",
       " [3759, 5, 15753, 4353, 283, 332],\n",
       " [62, 11941, 396, 3092, 120, 114],\n",
       " [7123, 3507, 65, 458, 3760, 28],\n",
       " [24024, 492, 0, 0, 0, 0],\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 6\n",
    "padding = 0\n",
    "#titles_arr = np.zeros((len(titles_to_num), max_len))\n",
    "\n",
    "for i in range(len(titles_to_num)):\n",
    "    if len(titles_to_num[i]) < max_len:\n",
    "        while len(titles_to_num[i]) < max_len:\n",
    "            titles_to_num[i].append(0)\n",
    "    else:\n",
    "        titles_to_num[i] = titles_to_num[i][:max_len]\n",
    "titles_to_num\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "municipal-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(max(titles_to_num, key=len)) == max_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "quiet-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[\"title_tokenized\"] = titles_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "exact-desire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>kw_category</th>\n",
       "      <th>article</th>\n",
       "      <th>title_cleaned</th>\n",
       "      <th>category_preprocessed</th>\n",
       "      <th>authors_onehot</th>\n",
       "      <th>title_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcc01a7a1a7f7092a2da6b9c5186fdef421c8ab6</td>\n",
       "      <td>pål solberg</td>\n",
       "      <td>Det er Trøndelag politidistrikt som klokken 1...</td>\n",
       "      <td>- Dette er ingen lekeplass</td>\n",
       "      <td>http://www.adressa.no/nyheter/sortrondelag/201...</td>\n",
       "      <td>nyheter sortrondelag</td>\n",
       "      <td>73905</td>\n",
       "      <td>lekeplass</td>\n",
       "      <td>[nyheter, sortrondelag]</td>\n",
       "      <td>0</td>\n",
       "      <td>[4647, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e1c14c3f599c9764a003740b9959c4e6f2fbc8e3</td>\n",
       "      <td>empty</td>\n",
       "      <td>Det er Trøndelag Veteranvognklubb TVK som for...</td>\n",
       "      <td>Trondheim fylles med veteranbiler</td>\n",
       "      <td>http://www.adressa.no/bil/veteran/article80867...</td>\n",
       "      <td>bil veteran</td>\n",
       "      <td>65918</td>\n",
       "      <td>trondheim fylles veteranbiler</td>\n",
       "      <td>[bil, veteran]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 6236, 15565, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6a0612e60690288a776834811004ce133f326cee</td>\n",
       "      <td>annemona grann</td>\n",
       "      <td>Historiene er nesten for utrolige og rommer e...</td>\n",
       "      <td>- Historiene er nesten for utrolige</td>\n",
       "      <td>http://www.adressa.no/kultur/2015/11/06/Histor...</td>\n",
       "      <td>kultur</td>\n",
       "      <td>30909</td>\n",
       "      <td>historiene nesten utrolige</td>\n",
       "      <td>[kultur]</td>\n",
       "      <td>2</td>\n",
       "      <td>[6237, 94, 4648, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13eb96b4cfbbc5954c54a75737afcac5ccc61779</td>\n",
       "      <td>elin fosshaug olsø</td>\n",
       "      <td>Flere bilførere reagerte med aggressiv kjørin...</td>\n",
       "      <td>Bilister aggressive mot trafikkaksjon</td>\n",
       "      <td>http://www.adressa.no/nyheter/trondheim/articl...</td>\n",
       "      <td>nyheter trondheim</td>\n",
       "      <td>5855</td>\n",
       "      <td>bilister aggressive trafikkaksjon</td>\n",
       "      <td>[nyheter, trondheim]</td>\n",
       "      <td>3</td>\n",
       "      <td>[1351, 11799, 23537, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b40a30877124510cf65683b6c9391d927e20f89d</td>\n",
       "      <td>ann iren bævre</td>\n",
       "      <td>Under årets store interiørmesse i Milano var ...</td>\n",
       "      <td>Fyll på med småbord</td>\n",
       "      <td>http://www.adressa.no/forbruker/hjem/article15...</td>\n",
       "      <td>forbruker hjem</td>\n",
       "      <td>52530</td>\n",
       "      <td>fyll småbord</td>\n",
       "      <td>[forbruker, hjem]</td>\n",
       "      <td>4</td>\n",
       "      <td>[3467, 23538, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 article_id              author  \\\n",
       "0  fcc01a7a1a7f7092a2da6b9c5186fdef421c8ab6         pål solberg   \n",
       "1  e1c14c3f599c9764a003740b9959c4e6f2fbc8e3               empty   \n",
       "2  6a0612e60690288a776834811004ce133f326cee      annemona grann   \n",
       "3  13eb96b4cfbbc5954c54a75737afcac5ccc61779  elin fosshaug olsø   \n",
       "4  b40a30877124510cf65683b6c9391d927e20f89d      ann iren bævre   \n",
       "\n",
       "                                                body  \\\n",
       "0   Det er Trøndelag politidistrikt som klokken 1...   \n",
       "1   Det er Trøndelag Veteranvognklubb TVK som for...   \n",
       "2   Historiene er nesten for utrolige og rommer e...   \n",
       "3   Flere bilførere reagerte med aggressiv kjørin...   \n",
       "4   Under årets store interiørmesse i Milano var ...   \n",
       "\n",
       "                                   title  \\\n",
       "0             - Dette er ingen lekeplass   \n",
       "1      Trondheim fylles med veteranbiler   \n",
       "2    - Historiene er nesten for utrolige   \n",
       "3  Bilister aggressive mot trafikkaksjon   \n",
       "4                    Fyll på med småbord   \n",
       "\n",
       "                                                 url            kw_category  \\\n",
       "0  http://www.adressa.no/nyheter/sortrondelag/201...  nyheter sortrondelag    \n",
       "1  http://www.adressa.no/bil/veteran/article80867...           bil veteran    \n",
       "2  http://www.adressa.no/kultur/2015/11/06/Histor...                 kultur   \n",
       "3  http://www.adressa.no/nyheter/trondheim/articl...     nyheter trondheim    \n",
       "4  http://www.adressa.no/forbruker/hjem/article15...        forbruker hjem    \n",
       "\n",
       "   article                      title_cleaned    category_preprocessed  \\\n",
       "0    73905                          lekeplass  [nyheter, sortrondelag]   \n",
       "1    65918      trondheim fylles veteranbiler           [bil, veteran]   \n",
       "2    30909         historiene nesten utrolige                 [kultur]   \n",
       "3     5855  bilister aggressive trafikkaksjon     [nyheter, trondheim]   \n",
       "4    52530                       fyll småbord        [forbruker, hjem]   \n",
       "\n",
       "   authors_onehot                title_tokenized  \n",
       "0               0          [4647, 0, 0, 0, 0, 0]  \n",
       "1               1      [1, 6236, 15565, 0, 0, 0]  \n",
       "2               2      [6237, 94, 4648, 0, 0, 0]  \n",
       "3               3  [1351, 11799, 23537, 0, 0, 0]  \n",
       "4               4      [3467, 23538, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-holocaust",
   "metadata": {},
   "source": [
    "### 1.2.3 Tokenize categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stretch-adult",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 41.94it/s]\n",
      "  0%|          | 0/74886 [00:00<?, ?it/s]/Users/eivindfalun/opt/anaconda3/envs/dnnrs/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "100%|██████████| 74886/74886 [02:01<00:00, 614.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fix categories from [nyheter, sport] to:[ [1] [3] ]\n",
    "\n",
    "# extract categories\n",
    "def get_categories(df, column):\n",
    "    categories = []\n",
    "    \n",
    "    def extract_category(_list):\n",
    "        for elem in _list:\n",
    "            if isinstance(elem, list):\n",
    "                extract_category(elem)\n",
    "            else:\n",
    "                if elem not in categories:\n",
    "                    categories.append(elem)\n",
    "    extract_category(df[column].values)\n",
    "    return categories\n",
    "\n",
    "unique_categories = get_categories(articles, \"category_preprocessed\") \n",
    "category_to_id = {category: idx + 1 for idx, category in enumerate(unique_categories)}\n",
    "id_to_category = {idx: category for idx, category in category_to_id.items()}\n",
    "category_to_id[\"0\"] = 0\n",
    "id_to_category[0] = \"0\"\n",
    "\n",
    "def onehotencode_category(df, column, max_len, padding):\n",
    "    i = 0\n",
    "    for i in tqdm(range(max_len)):\n",
    "        df[column + \"_\" + str(i)] = df[column].apply(lambda x: x[i] if i < len(x) else padding)\n",
    "    #df.drop(column, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "articles = onehotencode_category(articles, \"category_preprocessed\", 2, 0)\n",
    "\n",
    "def encode_categories(df):\n",
    "    for i in tqdm(range(len(df))):\n",
    "        df[\"category_preprocessed_0\"].iloc[i] = category_to_id[df[\"category_preprocessed_0\"].iloc[i]]\n",
    "        df[\"category_preprocessed_1\"].iloc[i] = category_to_id[str(df[\"category_preprocessed_1\"].iloc[i])]\n",
    "    return df\n",
    "articles = encode_categories(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "professional-salad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>kw_category</th>\n",
       "      <th>article</th>\n",
       "      <th>title_cleaned</th>\n",
       "      <th>category_preprocessed</th>\n",
       "      <th>authors_onehot</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>category_preprocessed_0</th>\n",
       "      <th>category_preprocessed_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcc01a7a1a7f7092a2da6b9c5186fdef421c8ab6</td>\n",
       "      <td>pål solberg</td>\n",
       "      <td>Det er Trøndelag politidistrikt som klokken 1...</td>\n",
       "      <td>- Dette er ingen lekeplass</td>\n",
       "      <td>http://www.adressa.no/nyheter/sortrondelag/201...</td>\n",
       "      <td>nyheter sortrondelag</td>\n",
       "      <td>73905</td>\n",
       "      <td>lekeplass</td>\n",
       "      <td>[nyheter, sortrondelag]</td>\n",
       "      <td>0</td>\n",
       "      <td>[4647, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 article_id       author  \\\n",
       "0  fcc01a7a1a7f7092a2da6b9c5186fdef421c8ab6  pål solberg   \n",
       "\n",
       "                                                body  \\\n",
       "0   Det er Trøndelag politidistrikt som klokken 1...   \n",
       "\n",
       "                        title  \\\n",
       "0  - Dette er ingen lekeplass   \n",
       "\n",
       "                                                 url            kw_category  \\\n",
       "0  http://www.adressa.no/nyheter/sortrondelag/201...  nyheter sortrondelag    \n",
       "\n",
       "   article title_cleaned    category_preprocessed  authors_onehot  \\\n",
       "0    73905     lekeplass  [nyheter, sortrondelag]               0   \n",
       "\n",
       "         title_tokenized category_preprocessed_0 category_preprocessed_1  \n",
       "0  [4647, 0, 0, 0, 0, 0]                       1                       2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-promise",
   "metadata": {},
   "source": [
    "### 1.2.4 Preprocess bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "published-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bodies(df):\n",
    "    df[\"body_cleaned\"] = df.body.apply(func = make_lower_case)\n",
    "    df[\"body_cleaned\"] = df.body_cleaned.apply(func = remove_stop_words)\n",
    "    df[\"body_cleaned\"] = df.body_cleaned.apply(func = remove_punctuation)\n",
    "    return df\n",
    "articles = clean_bodies(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "interpreted-edition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>kw_category</th>\n",
       "      <th>article</th>\n",
       "      <th>title_cleaned</th>\n",
       "      <th>category_preprocessed</th>\n",
       "      <th>authors_onehot</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>category_preprocessed_0</th>\n",
       "      <th>category_preprocessed_1</th>\n",
       "      <th>body_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcc01a7a1a7f7092a2da6b9c5186fdef421c8ab6</td>\n",
       "      <td>pål solberg</td>\n",
       "      <td>Det er Trøndelag politidistrikt som klokken 1...</td>\n",
       "      <td>- Dette er ingen lekeplass</td>\n",
       "      <td>http://www.adressa.no/nyheter/sortrondelag/201...</td>\n",
       "      <td>nyheter sortrondelag</td>\n",
       "      <td>73905</td>\n",
       "      <td>lekeplass</td>\n",
       "      <td>[nyheter, sortrondelag]</td>\n",
       "      <td>0</td>\n",
       "      <td>[4647, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>trøndelag politidistrikt klokken 15 50 melder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 article_id       author  \\\n",
       "0  fcc01a7a1a7f7092a2da6b9c5186fdef421c8ab6  pål solberg   \n",
       "\n",
       "                                                body  \\\n",
       "0   Det er Trøndelag politidistrikt som klokken 1...   \n",
       "\n",
       "                        title  \\\n",
       "0  - Dette er ingen lekeplass   \n",
       "\n",
       "                                                 url            kw_category  \\\n",
       "0  http://www.adressa.no/nyheter/sortrondelag/201...  nyheter sortrondelag    \n",
       "\n",
       "   article title_cleaned    category_preprocessed  authors_onehot  \\\n",
       "0    73905     lekeplass  [nyheter, sortrondelag]               0   \n",
       "\n",
       "         title_tokenized category_preprocessed_0 category_preprocessed_1  \\\n",
       "0  [4647, 0, 0, 0, 0, 0]                       1                       2   \n",
       "\n",
       "                                        body_cleaned  \n",
       "0  trøndelag politidistrikt klokken 15 50 melder ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-woman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "continuing-crown",
   "metadata": {},
   "source": [
    "## 1.1 Preprocessing specific to neural mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "serial-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename id to article_id and merge behaviors with articles to get more article features\n",
    "mf = sub_behaviors.copy() # true state: sub_behaviors -> behaviors \n",
    "mf.rename(columns={\"id\": \"article_id\"}, inplace=True)\n",
    "mf = mf.merge(articles[[\"article_id\", \"category_preprocessed\", \"authors_onehot\", \"title_tokenized\", \"category_preprocessed_0\", \"category_preprocessed_1\", \"body_cleaned\"]], on=\"article_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-pound",
   "metadata": {},
   "source": [
    "### 1.1.2 One-hot-encode categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-intake",
   "metadata": {},
   "source": [
    "### 1.1.3  Tokenize titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-playlist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-kenya",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "measured-karma",
   "metadata": {},
   "source": [
    "### 1.1.4 Author to num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-repair",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-forward",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "material-christianity",
   "metadata": {},
   "source": [
    "### 1.1.3 Set all instances to 1 (e.g. true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "close-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all clicks equal to 1 (e.g. true labels)\n",
    "rating = [1 for i in range(len(mf))]\n",
    "mf[\"rating\"] = rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-scotland",
   "metadata": {},
   "source": [
    "### 1.1.4 Clean up - fix ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "economic-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_enc = LabelEncoder()\n",
    "user_enc = LabelEncoder()\n",
    "mf[\"user\"] = user_enc.fit_transform(mf[\"user\"].values)\n",
    "mf[\"news_id\"] = article_enc.fit_transform(mf[\"article_id\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-trustee",
   "metadata": {},
   "source": [
    "## 1.2 Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "agricultural-microphone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>article_id</th>\n",
       "      <th>time</th>\n",
       "      <th>title_cleaned</th>\n",
       "      <th>category_preprocessed</th>\n",
       "      <th>authors_onehot</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>category_preprocessed_0</th>\n",
       "      <th>category_preprocessed_1</th>\n",
       "      <th>body_cleaned</th>\n",
       "      <th>rating</th>\n",
       "      <th>news_id</th>\n",
       "      <th>rank_latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6</td>\n",
       "      <td>Slik blir ferieåret 2017</td>\n",
       "      <td>frank lervik</td>\n",
       "      <td>f2ce698b3daf00cfcac0d5279053c4da9de07a92</td>\n",
       "      <td>2017-01-01 17:07:21</td>\n",
       "      <td>ferieåret 2017</td>\n",
       "      <td>[nyheter, sortrondelag]</td>\n",
       "      <td>16</td>\n",
       "      <td>[28069, 523, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>norge ti bevegelige helligdager falle hverdage...</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                            userId  \\\n",
       "0     0  cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6   \n",
       "\n",
       "                      title        author  \\\n",
       "0  Slik blir ferieåret 2017  frank lervik   \n",
       "\n",
       "                                 article_id                time  \\\n",
       "0  f2ce698b3daf00cfcac0d5279053c4da9de07a92 2017-01-01 17:07:21   \n",
       "\n",
       "    title_cleaned    category_preprocessed  authors_onehot  \\\n",
       "0  ferieåret 2017  [nyheter, sortrondelag]              16   \n",
       "\n",
       "            title_tokenized category_preprocessed_0 category_preprocessed_1  \\\n",
       "0  [28069, 523, 0, 0, 0, 0]                       1                       2   \n",
       "\n",
       "                                        body_cleaned  rating  news_id  \\\n",
       "0  norge ti bevegelige helligdager falle hverdage...       1     1125   \n",
       "\n",
       "   rank_latest  \n",
       "0          4.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf[\"rank_latest\"] = mf.groupby([\"user\"])[\"time\"].rank(method=\"first\", ascending=False)\n",
    "mf_train = mf[mf['rank_latest'] != 1]\n",
    "mf_test = mf[mf['rank_latest'] == 1]\n",
    "mf_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "humanitarian-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mf[\"news_id\"].max() + 1 == len(mf[\"news_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "extreme-adelaide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21668 21669\n"
     ]
    }
   ],
   "source": [
    "assert mf[\"user\"].max() + 1 == len(mf[\"user\"].unique())\n",
    "print(mf[\"user\"].max(), len(mf[\"user\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-frequency",
   "metadata": {},
   "source": [
    "## 1.3 Negative sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-ireland",
   "metadata": {},
   "source": [
    "### 1.3.1 Negative samling for two-tower model with category-feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "silent-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_id_to_cat0 = dict(zip(mf.news_id, mf.category_preprocessed_0))\n",
    "news_id_to_cat1 = dict(zip(mf.news_id, mf.category_preprocessed_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "center-tackle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21669\n",
      "21669\n",
      "21669\n"
     ]
    }
   ],
   "source": [
    "print(len(mf_train[\"user\"].unique()))\n",
    "print(len(mf[\"user\"].unique()))\n",
    "print(len(mf_test[\"user\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sample_two_tower_model(df, all_article_ids, all_user_ids):\n",
    "    \"\"\"\n",
    "    Return categories...\n",
    "    \"\"\"\n",
    "    \n",
    "    users, articles, category_1, category_2, labels = [], [], [], [],[]\n",
    "    user_item_set = set(zip(df[\"user\"], df[\"news_id\"], df[\"category_preprocessed_0\"], df[\"category_preprocessed_1\"]))\n",
    "    num_negatives = 4\n",
    "\n",
    "    for (u, i, c_0, c_1) in tqdm(user_item_set):\n",
    "        users.append(u)\n",
    "        articles.append(i)\n",
    "        category_1.append(c_0)\n",
    "        category_2.append(c_1)\n",
    "        labels.append(1)\n",
    "        for _ in range(num_negatives):\n",
    "            negative_item = np.random.choice(all_article_ids)\n",
    "            while (u, negative_item, c_0, c_1) in user_item_set:\n",
    "                negative_item = np.random.choice(all_article_ids)\n",
    "            users.append(u)\n",
    "            articles.append(negative_item)\n",
    "            \n",
    "            category_1.append(news_id_to_cat0[negative_item])\n",
    "            category_2.append(news_id_to_cat1[negative_item])\n",
    "            labels.append(0)\n",
    "    return np.asarray(users), np.asarray(articles), np.asarray(category_1), np.asarray(category_2), np.asarray(labels)\n",
    "\n",
    "all_article_ids_train = mf_train[\"news_id\"].unique()\n",
    "all_user_ids_train = mf_train[\"user\"].unique()\n",
    "\n",
    "#users, news_articles, category_1, category_2,labels = negative_sample_two_tower_feature_model(mf_train, all_article_ids_train, all_user_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#assert len(users) == len(news_articles) == len(category_1) == len(category_2) == len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-society",
   "metadata": {},
   "source": [
    "### 1.3.2 Negative sampling with multiple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "neutral-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_id_to_cat0 = dict(zip(mf.news_id, mf.category_preprocessed_0))\n",
    "news_id_to_cat1 = dict(zip(mf.news_id, mf.category_preprocessed_1))\n",
    "newsid_to_author = dict(zip(mf.news_id, mf.authors_onehot))\n",
    "newsid_to_title = dict(zip(mf.news_id, mf.title_tokenized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "pending-native",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90960/90960 [00:02<00:00, 38962.65it/s]\n"
     ]
    }
   ],
   "source": [
    "def negative_sample_two_tower_feature_model(df, all_article_ids, all_user_ids):\n",
    "    \"\"\"\n",
    "    Return user_ids, news_ids, category_1, category_2, authors_onehotencoded, titles\n",
    "    \"\"\"\n",
    "    \n",
    "    users, articles, category_1, category_2, authors, titles, labels = [], [], [], [],[], [], []\n",
    "    user_item_set = set(zip(df[\"user\"], \n",
    "                            df[\"news_id\"], \n",
    "                            df[\"category_preprocessed_0\"], \n",
    "                            df[\"category_preprocessed_1\"], \n",
    "                            df[\"authors_onehot\"]))\n",
    "    num_negatives = 4\n",
    "\n",
    "    for (u, i, c_0, c_1, author) in tqdm(user_item_set):\n",
    "        users.append(u)\n",
    "        articles.append(i)\n",
    "        category_1.append(c_0)\n",
    "        category_2.append(c_1)\n",
    "        authors.append(author)\n",
    "        titles.append(newsid_to_title[i])\n",
    "        labels.append(1)\n",
    "        for _ in range(num_negatives):\n",
    "            negative_item = np.random.choice(all_article_ids)\n",
    "            while (u, negative_item, c_0, c_1) in user_item_set:\n",
    "                negative_item = np.random.choice(all_article_ids)\n",
    "            users.append(u)\n",
    "            articles.append(negative_item)\n",
    "            \n",
    "            category_1.append(news_id_to_cat0[negative_item])\n",
    "            category_2.append(news_id_to_cat1[negative_item])\n",
    "            authors.append(newsid_to_author[negative_item])\n",
    "            titles.append(newsid_to_title[negative_item])\n",
    "            labels.append(0)\n",
    "    return np.asarray(users), np.asarray(articles), np.asarray(category_1), np.asarray(category_2), np.asarray(authors),titles, np.asarray(labels)\n",
    "\n",
    "all_article_ids_train = mf_train[\"news_id\"].unique()\n",
    "all_user_ids_train = mf_train[\"user\"].unique()\n",
    "\n",
    "users, news_articles, category_1, category_2, train_authors, train_titles, labels = negative_sample_two_tower_feature_model(mf_train, all_article_ids_train, all_user_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "exclusive-nevada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3098,   300,  2798,     0,     0,     0],\n",
       "       [  219,  1899, 12832,  1870,     0,     0],\n",
       "       [  800,    53,   111,  4264,  7796,     0],\n",
       "       ...,\n",
       "       [13620,   534,   177,  3437,   364,  1967],\n",
       "       [  101, 25717,   928,     0,     0,     0],\n",
       "       [14945,     1,  2404,  5283,     7, 21251]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for i in range()\n",
    "#train_titles[0] = np.array(train_titles[0])\n",
    "#y=numpy.array([numpy.array(xi) for xi in x])\n",
    "test_ = []\n",
    "for i in range(len(train_titles)):\n",
    "    \n",
    "    test_.append(train_titles[i][:6])\n",
    "        \n",
    "    \n",
    "        \n",
    "train_titles = np.array([np.array(xi) for xi in test_])\n",
    "train_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "going-gravity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>userId</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>article_id</th>\n",
       "      <th>time</th>\n",
       "      <th>title_cleaned</th>\n",
       "      <th>category_preprocessed</th>\n",
       "      <th>authors_onehot</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>category_preprocessed_0</th>\n",
       "      <th>category_preprocessed_1</th>\n",
       "      <th>body_cleaned</th>\n",
       "      <th>rating</th>\n",
       "      <th>news_id</th>\n",
       "      <th>rank_latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6</td>\n",
       "      <td>Slik blir ferieåret 2017</td>\n",
       "      <td>frank lervik</td>\n",
       "      <td>f2ce698b3daf00cfcac0d5279053c4da9de07a92</td>\n",
       "      <td>2017-01-01 17:07:21</td>\n",
       "      <td>ferieåret 2017</td>\n",
       "      <td>[nyheter, sortrondelag]</td>\n",
       "      <td>16</td>\n",
       "      <td>[28069, 523, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>norge ti bevegelige helligdager falle hverdage...</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cx:1011q8udhpdp823kp4a8u6tdsd:32ov38haips8f</td>\n",
       "      <td>Slik blir ferieåret 2017</td>\n",
       "      <td>frank lervik</td>\n",
       "      <td>f2ce698b3daf00cfcac0d5279053c4da9de07a92</td>\n",
       "      <td>2017-01-01 14:18:12</td>\n",
       "      <td>ferieåret 2017</td>\n",
       "      <td>[nyheter, sortrondelag]</td>\n",
       "      <td>16</td>\n",
       "      <td>[28069, 523, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>norge ti bevegelige helligdager falle hverdage...</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cx:101v4ycd1sfin1456ev4gyewlp:17jjqj6zeb2qt</td>\n",
       "      <td>Slik blir ferieåret 2017</td>\n",
       "      <td>frank lervik</td>\n",
       "      <td>f2ce698b3daf00cfcac0d5279053c4da9de07a92</td>\n",
       "      <td>2017-01-01 15:29:53</td>\n",
       "      <td>ferieåret 2017</td>\n",
       "      <td>[nyheter, sortrondelag]</td>\n",
       "      <td>16</td>\n",
       "      <td>[28069, 523, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>norge ti bevegelige helligdager falle hverdage...</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>cx:1095s7w0nz6973fry6x6a6ok2y:30w9pefm9xv45</td>\n",
       "      <td>Slik blir ferieåret 2017</td>\n",
       "      <td>frank lervik</td>\n",
       "      <td>f2ce698b3daf00cfcac0d5279053c4da9de07a92</td>\n",
       "      <td>2017-01-01 16:51:06</td>\n",
       "      <td>ferieåret 2017</td>\n",
       "      <td>[nyheter, sortrondelag]</td>\n",
       "      <td>16</td>\n",
       "      <td>[28069, 523, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>norge ti bevegelige helligdager falle hverdage...</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>cx:109jjai79rvwa3933affekcaxf:1htwz1j314bp2</td>\n",
       "      <td>Slik blir ferieåret 2017</td>\n",
       "      <td>frank lervik</td>\n",
       "      <td>f2ce698b3daf00cfcac0d5279053c4da9de07a92</td>\n",
       "      <td>2017-01-01 13:33:33</td>\n",
       "      <td>ferieåret 2017</td>\n",
       "      <td>[nyheter, sortrondelag]</td>\n",
       "      <td>16</td>\n",
       "      <td>[28069, 523, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>norge ti bevegelige helligdager falle hverdage...</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                            userId  \\\n",
       "0     0  cx:0d6120e0df4899ed1f18e5377c62644a:liav87wp9vf6   \n",
       "1     2       cx:1011q8udhpdp823kp4a8u6tdsd:32ov38haips8f   \n",
       "2     3       cx:101v4ycd1sfin1456ev4gyewlp:17jjqj6zeb2qt   \n",
       "3    18       cx:1095s7w0nz6973fry6x6a6ok2y:30w9pefm9xv45   \n",
       "4    20       cx:109jjai79rvwa3933affekcaxf:1htwz1j314bp2   \n",
       "\n",
       "                      title        author  \\\n",
       "0  Slik blir ferieåret 2017  frank lervik   \n",
       "1  Slik blir ferieåret 2017  frank lervik   \n",
       "2  Slik blir ferieåret 2017  frank lervik   \n",
       "3  Slik blir ferieåret 2017  frank lervik   \n",
       "4  Slik blir ferieåret 2017  frank lervik   \n",
       "\n",
       "                                 article_id                time  \\\n",
       "0  f2ce698b3daf00cfcac0d5279053c4da9de07a92 2017-01-01 17:07:21   \n",
       "1  f2ce698b3daf00cfcac0d5279053c4da9de07a92 2017-01-01 14:18:12   \n",
       "2  f2ce698b3daf00cfcac0d5279053c4da9de07a92 2017-01-01 15:29:53   \n",
       "3  f2ce698b3daf00cfcac0d5279053c4da9de07a92 2017-01-01 16:51:06   \n",
       "4  f2ce698b3daf00cfcac0d5279053c4da9de07a92 2017-01-01 13:33:33   \n",
       "\n",
       "    title_cleaned    category_preprocessed  authors_onehot  \\\n",
       "0  ferieåret 2017  [nyheter, sortrondelag]              16   \n",
       "1  ferieåret 2017  [nyheter, sortrondelag]              16   \n",
       "2  ferieåret 2017  [nyheter, sortrondelag]              16   \n",
       "3  ferieåret 2017  [nyheter, sortrondelag]              16   \n",
       "4  ferieåret 2017  [nyheter, sortrondelag]              16   \n",
       "\n",
       "            title_tokenized category_preprocessed_0 category_preprocessed_1  \\\n",
       "0  [28069, 523, 0, 0, 0, 0]                       1                       2   \n",
       "1  [28069, 523, 0, 0, 0, 0]                       1                       2   \n",
       "2  [28069, 523, 0, 0, 0, 0]                       1                       2   \n",
       "3  [28069, 523, 0, 0, 0, 0]                       1                       2   \n",
       "4  [28069, 523, 0, 0, 0, 0]                       1                       2   \n",
       "\n",
       "                                        body_cleaned  rating  news_id  \\\n",
       "0  norge ti bevegelige helligdager falle hverdage...       1     1125   \n",
       "1  norge ti bevegelige helligdager falle hverdage...       1     1125   \n",
       "2  norge ti bevegelige helligdager falle hverdage...       1     1125   \n",
       "3  norge ti bevegelige helligdager falle hverdage...       1     1125   \n",
       "4  norge ti bevegelige helligdager falle hverdage...       1     1125   \n",
       "\n",
       "   rank_latest  \n",
       "0          4.0  \n",
       "1          1.0  \n",
       "2          5.0  \n",
       "3          1.0  \n",
       "4          6.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-soccer",
   "metadata": {},
   "source": [
    "# 2 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "alpha-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Embedding, Reshape, Multiply, Dropout, Dense, Concatenate, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Layer, SpatialDropout1D, GlobalMaxPooling1D, Bidirectional, GRU\n",
    "from tensorflow.keras.layers import Dot, TimeDistributed, BatchNormalization\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-thomson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baking-thriller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article vocab size:  1192\n",
      "User vocab size:  21669\n",
      "Category vocab size: 266\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "article_embedding_input_dim = len(mf[\"news_id\"].unique())\n",
    "user_embedding_input_dim = len(mf[\"user\"].unique())\n",
    "category_embedding_input_dim = len(category_to_id)\n",
    "author_embedding_input_dim = len(authors_to_id) + 1\n",
    "print(\"Article vocab size: \", article_embedding_input_dim)\n",
    "print(\"User vocab size: \", user_embedding_input_dim)\n",
    "print(\"Category vocab size:\", category_embedding_input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_tower_feature_model(article_embedding_input_dim,\n",
    "                           user_embedding_input_dim,\n",
    "                           category_embedding_input_dim, # TODO: fix\n",
    "                           author_embedding_input_dim): # TODO: fix\n",
    "    \n",
    "    user_id_input = Input(shape=(1,), name=\"user_id\")\n",
    "    item_id_input = Input(shape=(1,), name=\"article_id\")\n",
    "    \n",
    "    first_category = Input(shape=(1,), name=\"first_category\")\n",
    "    second_category = Input(shape=(1,), name=\"second_category\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    embedding_user_size = 20\n",
    "    embedding_item_size = 20\n",
    "    embedding_category_size = 20\n",
    "    \n",
    "    user_embedding = Embedding(input_dim=user_embedding_input_dim, output_dim=embedding_user_size, input_length=1, name=\"user_embedding\")(user_id_input)\n",
    "    item_embedding = Embedding(input_dim=article_embedding_input_dim, output_dim=embedding_item_size, input_length=1, name=\"item_embedding\")(item_id_input)\n",
    "    category_embedding = Embedding(input_dim=category_embedding_input_dim, output_dim=embedding_category_size, input_length=1, name=\"category_embedding\")\n",
    "    \n",
    "    \n",
    "    first_category_embedding = category_embedding(first_category)\n",
    "    second_category_embedding = category_embedding(second_category)\n",
    "    # reshape from (batch_size, input_length, embedding_size) to (batch_size, embedding_size)\n",
    "    user_vecs = Reshape([embedding_user_size])(user_embedding)\n",
    "    item_vecs = Reshape([embedding_item_size])(item_embedding)\n",
    "    category_vecs_1 = Reshape([embedding_category_size])(first_category_embedding)\n",
    "    category_vecs_2 = Reshape([embedding_category_size])(second_category_embedding)\n",
    "\n",
    "    item_vecs_complete = Concatenate()([item_vecs, category_vecs_1, category_vecs_2,])\n",
    "    \n",
    "    input_vecs = Concatenate()([user_vecs, item_vecs_complete])\n",
    "    \n",
    "    x = Dense(128, activation=\"relu\")(input_vecs)\n",
    "    y = Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=[user_id_input, item_id_input, first_category, second_category], outputs=y)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.01),\n",
    "        loss=tf.losses.MSE,\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "two_tower_feat = two_tower_feature_model(article_embedding_input_dim,\n",
    "                                        user_embedding_input_dim,\n",
    "                                        category_embedding_input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = two_tower_feat.fit([users, news_articles, category_1, category_2], labels, batch_size=64, epochs=3, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(users, news_articles, category_1, category_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-coordination",
   "metadata": {},
   "source": [
    "## 2.2 Model with categories and authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "important-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_embedding_input_dim = len(authors_to_id) +1\n",
    "title_vocab_size = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_tower_feature_model(article_embedding_input_dim,\n",
    "                           user_embedding_input_dim,\n",
    "                           category_embedding_input_dim,\n",
    "                            author_embedding_input_dim,\n",
    "                           title_vocab_size): #title_vocab_size\n",
    "    \n",
    "    user_id_input = Input(shape=(1,), name=\"user_id\")\n",
    "    item_id_input = Input(shape=(1,), name=\"article_id\")\n",
    "    \n",
    "    first_category = Input(shape=(1,), name=\"first_category\")\n",
    "    second_category = Input(shape=(1,), name=\"second_category\")\n",
    "    \n",
    "    authors = Input(shape=(1,), name=\"authors\")\n",
    "    titles = Input(shape=(6,), name=\"title\")\n",
    "    \n",
    "    embedding_user_size = 20\n",
    "    embedding_item_size = 20\n",
    "    embedding_category_size = 20\n",
    "    embedding_author_size = 20\n",
    "    embedding_title_size = 20\n",
    "    \n",
    "    user_embedding = Embedding(input_dim=user_embedding_input_dim, output_dim=embedding_user_size, input_length=1, name=\"user_embedding\")(user_id_input)\n",
    "    item_embedding = Embedding(input_dim=article_embedding_input_dim, output_dim=embedding_item_size, input_length=1, name=\"item_embedding\")(item_id_input)\n",
    "    category_embedding = Embedding(input_dim=category_embedding_input_dim, output_dim=embedding_category_size, input_length=1, name=\"category_embedding\")\n",
    "    \n",
    "    first_category_embedding = category_embedding(first_category)\n",
    "    second_category_embedding = category_embedding(second_category)\n",
    "    \n",
    "    author_embedding = Embedding(input_dim=author_embedding_input_dim, output_dim=embedding_author_size)(authors)\n",
    "    title_embedding = Embedding(input_dim=title_vocab_size, output_dim=embedding_title_size)(titles)\n",
    "    title_embedding = GlobalAveragePooling1D()(title_embedding)\n",
    "    \n",
    "    # reshape from (batch_size, input_length, embedding_size) to (batch_size, embedding_size)\n",
    "    user_vecs = Reshape([embedding_user_size])(user_embedding)\n",
    "    item_vecs = Reshape([embedding_item_size])(item_embedding)\n",
    "    category_vecs_1 = Reshape([embedding_category_size])(first_category_embedding)\n",
    "    category_vecs_2 = Reshape([embedding_category_size])(second_category_embedding)\n",
    "    \n",
    "    author_vecs = Reshape([embedding_author_size])(author_embedding)\n",
    "    title_vecs = Reshape([embedding_title_size])(title_embedding)\n",
    "    \n",
    "\n",
    "    item_vecs_complete = Concatenate()([item_vecs, \n",
    "                                        category_vecs_1, \n",
    "                                        category_vecs_2,  \n",
    "                                        author_vecs, \n",
    "                                        title_vecs])\n",
    "    \n",
    "    input_vecs = Concatenate()([user_vecs, item_vecs_complete])\n",
    "    \n",
    "    x = Dense(128, activation=\"relu\")(input_vecs)\n",
    "    y = Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=[user_id_input, \n",
    "                                item_id_input, \n",
    "                                first_category, \n",
    "                                second_category, authors, titles], outputs=y) #titles\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.01),\n",
    "        loss=tf.losses.binary_crossentropy,\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "two_tower_feat = two_tower_feature_model(article_embedding_input_dim,\n",
    "                                        user_embedding_input_dim,\n",
    "                                        category_embedding_input_dim,\n",
    "                                         author_embedding_input_dim,\n",
    "                                        title_vocab_size)\n",
    "\n",
    "\n",
    "# MSE vs bin_crossentropy: https://susanqq.github.io/tmp_post/2017-09-05-crossentropyvsmes/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(i.shape, i.dtype) for i in two_tower_feat.inputs]\n",
    "[print(o.shape, o.dtype) for o in two_tower_feat.outputs]\n",
    "[print(l.name, l.input_shape, l.dtype) for l in two_tower_feat.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = two_tower_feat.fit([users, news_articles, category_1, category_2, train_authors, train_titles ], labels, batch_size=64, epochs=3, validation_split=0.1)\n",
    "#train_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-tamil",
   "metadata": {},
   "source": [
    "### Two tower model with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "broke-scenario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 20)\n"
     ]
    }
   ],
   "source": [
    "def two_tower_attention_model(article_embedding_input_dim,\n",
    "                           user_embedding_input_dim,\n",
    "                           category_embedding_input_dim,\n",
    "                            author_embedding_input_dim,\n",
    "                           title_vocab_size): #title_vocab_size\n",
    "    \n",
    "    user_id_input = Input(shape=(1,), name=\"user_id\")\n",
    "    item_id_input = Input(shape=(1,), name=\"article_id\")\n",
    "    \n",
    "    first_category = Input(shape=(1,), name=\"first_category\")\n",
    "    second_category = Input(shape=(1,), name=\"second_category\")\n",
    "    \n",
    "    authors = Input(shape=(1,), name=\"authors\")\n",
    "    titles = Input(shape=(6,), name=\"title\")\n",
    "    \n",
    "    embedding_user_size = 20\n",
    "    embedding_item_size = 20\n",
    "    embedding_category_size = 20\n",
    "    embedding_author_size = 20\n",
    "    embedding_title_size = 20\n",
    "    \n",
    "    user_embedding = Embedding(input_dim=user_embedding_input_dim, output_dim=embedding_user_size, input_length=1, name=\"user_embedding\")(user_id_input)\n",
    "    item_embedding = Embedding(input_dim=article_embedding_input_dim, output_dim=embedding_item_size, input_length=1, name=\"item_embedding\")(item_id_input)\n",
    "    category_embedding = Embedding(input_dim=category_embedding_input_dim, output_dim=embedding_category_size, input_length=1, name=\"category_embedding\")\n",
    "    \n",
    "    first_category_embedding = category_embedding(first_category)\n",
    "    second_category_embedding = category_embedding(second_category)\n",
    "    \n",
    "    author_embedding = Embedding(input_dim=author_embedding_input_dim, output_dim=embedding_author_size)(authors)\n",
    "    title_embedding = Embedding(input_dim=title_vocab_size, output_dim=embedding_title_size, name=\"title_embedding\")(titles)\n",
    "    \n",
    "    rnn_outs = Bidirectional(GRU(64, return_sequences=True), name=\"gru\")(title_embedding)\n",
    "    sentence, word_scores = Attention(return_attention=True, name=\"attention_vec\")(rnn_outs)\n",
    "    fc_sentence = Dense(20, activation=\"relu\")(sentence)\n",
    "    print(fc_sentence.shape)\n",
    "    #title_embedding = GlobalAveragePooling1D()(title_embedding)\n",
    "    \n",
    "    # reshape from (batch_size, input_length, embedding_size) to (batch_size, embedding_size)\n",
    "    user_vecs = Reshape([embedding_user_size])(user_embedding)\n",
    "    item_vecs = Reshape([embedding_item_size])(item_embedding)\n",
    "    category_vecs_1 = Reshape([embedding_category_size])(first_category_embedding)\n",
    "    category_vecs_2 = Reshape([embedding_category_size])(second_category_embedding)\n",
    "    \n",
    "    author_vecs = Reshape([embedding_author_size])(author_embedding)\n",
    "    #title_vecs = Reshape([embedding_title_size])(title_embedding)\n",
    "    \n",
    "\n",
    "    item_vecs_complete = Concatenate()([item_vecs, \n",
    "                                        category_vecs_1, \n",
    "                                        category_vecs_2,  \n",
    "                                        author_vecs, \n",
    "                                        fc_sentence])\n",
    "    \n",
    "    input_vecs = Concatenate()([user_vecs, item_vecs_complete])\n",
    "    \n",
    "    x = Dense(128, activation=\"relu\")(input_vecs)\n",
    "    y = Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=[user_id_input, \n",
    "                                item_id_input, \n",
    "                                first_category, \n",
    "                                second_category, authors, titles], outputs=y) #titles\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.01),\n",
    "        loss=tf.losses.binary_crossentropy,\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "two_tower_attention = two_tower_attention_model(article_embedding_input_dim,\n",
    "                                        user_embedding_input_dim,\n",
    "                                        category_embedding_input_dim,\n",
    "                                         author_embedding_input_dim,\n",
    "                                        title_vocab_size)\n",
    "\n",
    "\n",
    "# MSE vs bin_crossentropy: https://susanqq.github.io/tmp_post/2017-09-05-crossentropyvsmes/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "marked-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[print(i.shape, i.dtype) for i in two_tower_attention.inputs]\n",
    "#[print(o.shape, o.dtype) for o in two_tower_attention.outputs]\n",
    "#[print(l.name, l.input_shape, l.dtype) for l in two_tower_attention.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "toxic-compensation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6396/6396 [==============================] - 122s 19ms/step - loss: 0.8724 - accuracy: 0.9341 - val_loss: 3.0850 - val_accuracy: 0.8000\n",
      "Epoch 2/3\n",
      "6396/6396 [==============================] - 121s 19ms/step - loss: 3.0934 - accuracy: 0.7995 - val_loss: 3.0850 - val_accuracy: 0.8000\n",
      "Epoch 3/3\n",
      "6396/6396 [==============================] - 123s 19ms/step - loss: 3.0934 - accuracy: 0.7995 - val_loss: 3.0850 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "history_3 = two_tower_attention.fit([users, news_articles, category_1, category_2, train_authors, train_titles ], labels, batch_size=64, epochs=3, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "painted-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % rgb\n",
    "\n",
    "def attention2color(attention_score):\n",
    "    r = 255 - int(attention_score*255)\n",
    "    color= rgb_to_hex((255, r, r))\n",
    "    return str(color)\n",
    "\n",
    "def visualize_attention(model, user, item, c_0, c_1, author, title, idx_to_word):\n",
    "    \"\"\"\n",
    "    Inspire\n",
    "    \n",
    "    Params: \n",
    "        model: trained attention model\n",
    "        test_array: array consisting of (users, news_articles, category_1, category_2, authors, titles)\n",
    "        idx_to_word: map each word_index in the title to word\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # a= np.expand_dims(np.array(users[0]), axis=0)\n",
    "    items_to_predict = [np.expand_dims(np.array(user), 0), \n",
    "                       np.expand_dims(np.array(item), 0),\n",
    "                       np.expand_dims(np.array(c_0), 0),\n",
    "                       np.expand_dims(np.array(c_1), 0),\n",
    "                       np.expand_dims(np.array(author), 0),\n",
    "                       np.expand_dims(np.array(title), 0)]\n",
    "    \n",
    "    \n",
    "    model_attention = keras.Model(inputs=model.input, \n",
    "                        outputs=[model.output, model.get_layer(\"attention_vec\").output[-1]])\n",
    "    label_probs, attentions = model_attention.predict(items_to_predict)\n",
    "    \n",
    "    idx_words = title\n",
    "    decoded_text = [idx_to_word[idx] for idx in idx_words]\n",
    "    \n",
    "    attentions = attentions[0]\n",
    "    attentions_text = (attentions - np.min(attentions)) / (np.max(attentions) - np.min(attentions)) # TODO: justify normalization\n",
    "    \n",
    "    token_attention_dict = {}\n",
    "    for token, attention_score in zip(decoded_text, attentions_text):\n",
    "        token_attention_dict[token] = attention_score\n",
    "    \n",
    "    print(token_attention_dict)\n",
    "    html_text = \"<hr><p style='font-size: large'><b>Text:  </b>\"\n",
    "    for token, attention in token_attention_dict.items():\n",
    "        html_text += \"<span style='background-color:{};'>{} <span> \".format(attention2color(attention), token)\n",
    "    display(HTML(html_text))\n",
    "    \n",
    "            \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "featured-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_attention(two_tower_attention,2, 1125, 1,2,16,[28069, 523, 0, 0, 0, 0],reverse_word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "champion-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(model, user_id, all_article_ids):\n",
    "    \"\"\"\n",
    "        Params: \n",
    "            model: the model\n",
    "            user_id: the user we want predictions for\n",
    "            all_article_ids:\n",
    "            \n",
    "        Return: \n",
    "            article_ids\n",
    "    \"\"\"\n",
    "    #test_user_item_set = set(zip(mf_test[\"user\"], mf_test[\"news_id\"], mf_test[\"category_preprocessed_0\"], mf_test[\"category_preprocessed_1\"]))\n",
    "    user_interacted_items = mf.groupby(\"user\")[\"news_id\"].apply(list).to_dict()\n",
    "    \n",
    "    #user_id, article_id, cat_1, cat_2, title_t = mf[\"user\"].iloc[0], mf[\"news_id\"].iloc[0], mf[\"category_preprocessed_0\"].iloc[0], mf[\"category_preprocessed_1\"].iloc[0], mf[\"title_tokenized\"].iloc[0]\n",
    "    c_0, c_1, titles, authors = [], [], [], []\n",
    "    article_id = mf_test[mf_test[\"user\"] == user_id][\"news_id\"].values[0]\n",
    "    \n",
    "    interacted_items = user_interacted_items[user_id] # user_id\n",
    "    not_interacted_items = set(all_article_ids) - set(interacted_items)\n",
    "    selected_not_interacted = list(np.random.choice(list(not_interacted_items),99))\n",
    "    test_items = selected_not_interacted + [article_id]\n",
    "    for elem in test_items:\n",
    "        c_0.append(news_id_to_cat0[elem])\n",
    "        c_1.append(news_id_to_cat1[elem])\n",
    "        titles.append(newsid_to_title[elem])\n",
    "        authors.append(newsid_to_author[elem])\n",
    "    assert len(c_0) == len(c_1) == len(titles) == 100\n",
    "    \n",
    "    preds = model.predict([np.array([user_id]*100), # user_id\n",
    "                               np.array(test_items), \n",
    "                               np.array(c_0), \n",
    "                               np.array(c_1), \n",
    "                               np.array(authors),\n",
    "                               np.array(titles)])\n",
    "    pred_labels = np.squeeze(preds)\n",
    "\n",
    "    top10_items = [test_items[i] for i in np.argsort(pred_labels)[::-1][0:10].tolist()]\n",
    "    \n",
    "    return top10_items\n",
    "\n",
    "recs = generate_recommendations(two_tower_attention, 2, mf[\"news_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "applied-aurora",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have read: \n",
      "1125   Slik blir ferieåret 2017\n",
      "740   Nødbluss sendt gjennom vindu startet branntilløp\n",
      "30   På dette bildet skiller Magnus Carlsen seg ut: - Litt tilfeldig\n",
      "709   Se lesernes nyttårsbilder\n",
      "\n",
      "-------------------\n",
      "\n",
      "Top 10 recommendations \n",
      "\n",
      "861 To kaldeste novemberdøgn i Trøndelag på 90 år\n",
      "WARNING:tensorflow:5 out of the last 805 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8d7b3f4b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "{'to': 1.0, 'kaldeste': 0.0034951915, 'novemberdøgn': 0.00029116444, 'trøndelag': 0.0, '90': 2.802001e-05, 'år': 2.4365224e-06}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ff0000;'>to <span> <span style='background-color:#ffffff;'>kaldeste <span> <span style='background-color:#ffffff;'>novemberdøgn <span> <span style='background-color:#ffffff;'>trøndelag <span> <span style='background-color:#ffffff;'>90 <span> <span style='background-color:#ffffff;'>år <span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322 - Nordmenn var mistenkt for doping av FIS\n",
      "WARNING:tensorflow:6 out of the last 806 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8d7ce0cf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "{'nordmenn': 1.0, 'mistenkt': 0.029807728, 'doping': 0.0068156435, 'fis': 0.0021248797, '': 1.10420315e-05}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ff0000;'>nordmenn <span> <span style='background-color:#fff8f8;'>mistenkt <span> <span style='background-color:#fffefe;'>doping <span> <span style='background-color:#ffffff;'>fis <span> <span style='background-color:#ffffff;'> <span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885 Oppdal flyplass, Fagerhaug\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8d7cb0db00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "{'oppdal': 1.0, 'flyplass': 0.03099891, 'fagerhaug': 0.010274553, '': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ff0000;'>oppdal <span> <span style='background-color:#fff8f8;'>flyplass <span> <span style='background-color:#fffdfd;'>fagerhaug <span> <span style='background-color:#ffffff;'> <span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1154 Syv sosiale medier som barna kjenner bedre enn deg\n",
      "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8d7a5dcc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "{'syv': 1.0, 'sosiale': 0.0010458861, 'medier': 9.216412e-05, 'barna': 3.8061877e-05, 'kjenner': 0.0, 'bedre': 1.2506046e-05}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ff0000;'>syv <span> <span style='background-color:#ffffff;'>sosiale <span> <span style='background-color:#ffffff;'>medier <span> <span style='background-color:#ffffff;'>barna <span> <span style='background-color:#ffffff;'>kjenner <span> <span style='background-color:#ffffff;'>bedre <span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332 Bestefar dømt til fem år for overgrep mot to barnebarn\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8d76603b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "{'bestefar': 1.0, 'dømt': 0.00225093, 'fem': 0.0, 'år': 5.5314467e-05, 'overgrep': 4.2038995e-05, 'to': 0.00010104109}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ff0000;'>bestefar <span> <span style='background-color:#ffffff;'>dømt <span> <span style='background-color:#ffffff;'>fem <span> <span style='background-color:#ffffff;'>år <span> <span style='background-color:#ffffff;'>overgrep <span> <span style='background-color:#ffffff;'>to <span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332 Bestefar dømt til fem år for overgrep mot to barnebarn\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8d784353b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "{'bestefar': 1.0, 'dømt': 0.00225093, 'fem': 0.0, 'år': 5.5314467e-05, 'overgrep': 4.2038995e-05, 'to': 0.00010104109}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ff0000;'>bestefar <span> <span style='background-color:#ffffff;'>dømt <span> <span style='background-color:#ffffff;'>fem <span> <span style='background-color:#ffffff;'>år <span> <span style='background-color:#ffffff;'>overgrep <span> <span style='background-color:#ffffff;'>to <span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846 E6 Hjerkinn\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8d7835ae60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "{'e6': 1.0, 'hjerkinn': 0.0066309557, '': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ff0000;'>e6 <span> <span style='background-color:#fffefe;'>hjerkinn <span> <span style='background-color:#ffffff;'> <span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546 Frykter at gode fiskeplasser går tapt til Salmars nye havmerd\n",
      "WARNING:tensorflow:9 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8d76fa1290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "{'frykter': 1.0, 'gode': 0.052780543, 'fiskeplasser': 0.001716885, 'går': 8.225235e-05, 'tapt': 0.0, 'salmars': 1.0304964e-06}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ff0000;'>frykter <span> <span style='background-color:#fff2f2;'>gode <span> <span style='background-color:#ffffff;'>fiskeplasser <span> <span style='background-color:#ffffff;'>går <span> <span style='background-color:#ffffff;'>tapt <span> <span style='background-color:#ffffff;'>salmars <span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923 Rørlegger Mari (29) deltar i ny ekstrem-reality\n",
      "WARNING:tensorflow:10 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8d77b36560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "{'rørlegger': 1.0, 'mari': 0.008019812, '29': 0.00021595886, 'deltar': 4.363401e-05, 'ny': 0.0, 'ekstremreality': 3.360998e-05}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ff0000;'>rørlegger <span> <span style='background-color:#fffdfd;'>mari <span> <span style='background-color:#ffffff;'>29 <span> <span style='background-color:#ffffff;'>deltar <span> <span style='background-color:#ffffff;'>ny <span> <span style='background-color:#ffffff;'>ekstremreality <span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828 Norges sprøeste bilrace\n",
      "WARNING:tensorflow:11 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8d7cea3440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "{'norges': 1.0, 'sprøeste': 0.017068997, 'bilrace': 0.0028344116, '': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ff0000;'>norges <span> <span style='background-color:#fffbfb;'>sprøeste <span> <span style='background-color:#ffffff;'>bilrace <span> <span style='background-color:#ffffff;'> <span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_recommendations(recs, user_id):\n",
    "    #TODO: there is something wrong with the attention-display and the corresponding title-recommendation\n",
    "    \"\"\"\n",
    "        Params:\n",
    "            recs: list with 10 item_ids\n",
    "            user_id: the user id for which 10 recommendations is provided\n",
    "        Return:\n",
    "            print read-history, and vi\n",
    "    \"\"\" \n",
    "    user_history = mf[mf[\"user\"] == user_id]\n",
    "    read_history = user_history[\"title\"].values[0:4]\n",
    "    news_ids_history = user_history[\"news_id\"].values[0:4]\n",
    "    print(\"You have read: \")\n",
    "    for news_ids_history, hist in zip(news_ids_history, read_history):\n",
    "        print(news_ids_history, \" \", hist)\n",
    "    \n",
    "    print(\"\\n-------------------\\n\")\n",
    "    print(\"Top {} recommendations\".format(len(recs)), \"\\n\")\n",
    "    for item in recs:\n",
    "        item_df = mf[mf[\"news_id\"] == item]\n",
    "        title = item_df[\"title\"].values[0]\n",
    "        idx = item_df[\"news_id\"].values[0]\n",
    "        print(idx, title)\n",
    "        \n",
    "        c_0 = item_df[\"category_preprocessed_0\"].values[0]\n",
    "        c_1 = item_df[\"category_preprocessed_1\"].values[0]\n",
    "        author = item_df[\"authors_onehot\"].values[0]\n",
    "        title_tokenized = item_df[\"title_tokenized\"].values[0]\n",
    "        visualize_attention(two_tower_attention, user_id, idx, c_0, c_1, author, title_tokenized, reverse_word_map)\n",
    "        \n",
    "visualize_recommendations(recs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf[mf[\"user\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-roulette",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-launch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-certificate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-community",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-bracket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-carpet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-duncan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-ecology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reverse-lodging",
   "metadata": {},
   "source": [
    "# Testing, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acting-henry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 199/21669 [00:10<19:44, 18.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-5b7d54029660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hit Ratio @ 10 is {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mhit_ratio_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"news_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwo_tower_attention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-5b7d54029660>\u001b[0m in \u001b[0;36mhit_ratio_features\u001b[0;34m(mf_test, mf, all_article_ids, model)\u001b[0m\n\u001b[1;32m     24\u001b[0m                                \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                np.array(titles)])\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dnnrs/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1623\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dnnrs/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dnnrs/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dnnrs/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dnnrs/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dnnrs/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2970\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 2972\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   2973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def hit_ratio_features(mf_test, mf, all_article_ids, model):\n",
    "    test_user_item_set = set(zip(mf_test[\"user\"], mf_test[\"news_id\"], mf_test[\"category_preprocessed_0\"], mf_test[\"category_preprocessed_1\"]))\n",
    "    user_interacted_items = mf.groupby(\"user\")[\"news_id\"].apply(list).to_dict()\n",
    "    hits = []\n",
    "    for (u,i, c_1,c_2) in tqdm(test_user_item_set):\n",
    "        c_0 = []\n",
    "        c_1 = []\n",
    "        titles = []\n",
    "        authors = []\n",
    "        interacted_items = user_interacted_items[u]\n",
    "        not_interacted_items = set(all_article_ids) - set(interacted_items)\n",
    "        selected_not_interacted = list(np.random.choice(list(not_interacted_items),99))\n",
    "        test_items = selected_not_interacted + [i]\n",
    "        for elem in test_items:\n",
    "            c_0.append(news_id_to_cat0[elem])\n",
    "            c_1.append(news_id_to_cat1[elem])\n",
    "            titles.append(newsid_to_title[elem])\n",
    "            authors.append(newsid_to_author[elem])\n",
    "        assert len(c_0) == len(c_1) == len(titles) == 100\n",
    "        \n",
    "        preds = model.predict([np.array([u]*100), \n",
    "                               np.array(test_items), \n",
    "                               np.array(c_0), \n",
    "                               np.array(c_1), \n",
    "                               np.array(authors),\n",
    "                               np.array(titles)])\n",
    "\n",
    "        pred_labels = np.squeeze(preds)\n",
    "\n",
    "        top10_items = [test_items[i] for i in np.argsort(pred_labels)[::-1][0:10].tolist()]\n",
    "\n",
    "        if i in top10_items:\n",
    "            hits.append(1)\n",
    "        else:\n",
    "            hits.append(0)\n",
    "    print(\"Hit Ratio @ 10 is {:.2f}\".format(np.average(hits)))\n",
    "hit_ratio_features(mf_test, mf, mf[\"news_id\"].unique(), two_tower_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-pontiac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-television",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-disaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = two_tower_feat.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_embedding = weights[1]\n",
    "len(category_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "category_tsne = TSNE(perplexity=20).fit_transform(category_embedding)\n",
    "a = pd.DataFrame(category_tsne)\n",
    "a.columns=[\"x\", \"y\"]\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.scatter(a[\"x\"], a[\"y\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles = articles.copy()\n",
    "article_label_enc = LabelEncoder()\n",
    "test_articles[\"news_id\"] = article_label_enc.fit_transform(test_articles[\"article_id\"].values)\n",
    "test_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=\"word\",\n",
    "                            ngram_range=(1,2),\n",
    "                            min_df=0.003,\n",
    "                            max_df=0.5,\n",
    "                            max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids = mf[\"news_id\"].unique().tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(mf[\"title_cleaned\"] + \"\" +mf[\"body_cleaned\"])\n",
    "tfidf_feature_names = vectorizer.get_feature_names()\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_profile(item_id):\n",
    "    idx = item_ids.index(item_id)\n",
    "    item_profile = tfidf_matrix[idx:idx+1]\n",
    "    return item_profile\n",
    "\n",
    "def get_item_profiles(ids):\n",
    "    item_profiles_list = [get_item_profile(x) for x in ids]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles\n",
    "\n",
    "def build_user_profile(person_id, interactions_indexed_df):\n",
    "    interactions_person_df = interactions_indexed_df.loc[person_id]\n",
    "    user_item_profiles = get_item_profiles(interactions_person_df[\"news_id\"])\n",
    "    \n",
    "    user_profile_norm = sklearn.preprocessing.normalize(user_item_profiles)\n",
    "    return user_profile_norm\n",
    "\n",
    "def get_profile(idx):\n",
    "    interactions = mf[mf[\"user\"] == idx]\n",
    "    profile = build_user_profile(idx, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_item_profiles([1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf[mf[\"user\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "social-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util classes\n",
    "class Attention(Layer):\n",
    "    # this is fetched from: https://www.kaggle.com/alber8295/bigru-w-attention-visualized-for-beginners\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, return_attention=False,\n",
    "                 **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = K.squeeze(K.dot(x, K.expand_dims(self.W)), axis=-1)\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        weighted_input = x * K.expand_dims(a)\n",
    "\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [result, a]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], input_shape[-1]),\n",
    "                    (input_shape[0], input_shape[1])]\n",
    "        else:\n",
    "            return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention_from_online(model, tokenizer):\n",
    "    # Make new model for output predictions and attentions\n",
    "    '''\n",
    "    model.get_layer('attention_vec').output:\n",
    "    attention_vec (Attention)    [(None, 128), (None, 54)] <- We want (None,54) that is the word att\n",
    "    '''\n",
    "    model_att = Model(inputs=model.input, \\\n",
    "                            outputs=[model.output, model.get_layer('attention_vec').output[-1]])\n",
    "    idx = np.random.randint(low = 0, high=X_te.shape[0]) # Get a random test\n",
    "    tokenized_sample = np.trim_zeros(X_te[idx]) # Get the tokenized text\n",
    "    label_probs, attentions = model_att.predict(X_te[idx:idx+1]) # Perform the prediction\n",
    "\n",
    "    # Get decoded text and labels\n",
    "    id2word = dict(map(reversed, tokenizer.word_index.items()))\n",
    "    decoded_text = [id2word[word] for word in tokenized_sample] \n",
    "    \n",
    "    # Get classification\n",
    "    label = (label_probs>0.5).astype(int).squeeze() # Only one\n",
    "    label2id = ['Sincere', 'Insincere']\n",
    "\n",
    "    # Get word attentions using attenion vector\n",
    "    token_attention_dic = {}\n",
    "    max_score = 0.0\n",
    "    min_score = 0.0\n",
    "    \n",
    "    attentions_text = attentions[0,-len(tokenized_sample):]\n",
    "    #plt.bar(np.arange(0,len(attentions.squeeze())), attentions.squeeze())\n",
    "    #plt.show();\n",
    "    #print(attentions_text)\n",
    "    attentions_text = (attentions_text - np.min(attentions_text)) / (np.max(attentions_text) - np.min(attentions_text))\n",
    "    for token, attention_score in zip(decoded_text, attentions_text):\n",
    "        #print(token, attention_score)\n",
    "        token_attention_dic[token] = attention_score\n",
    "        \n",
    "\n",
    "    # Build HTML String to viualize attentions\n",
    "    html_text = \"<hr><p style='font-size: large'><b>Text:  </b>\"\n",
    "    for token, attention in token_attention_dic.items():\n",
    "        html_text += \"<span style='background-color:{};'>{} <span> \".format(attention2color(attention),\n",
    "                                                                            token)\n",
    "    #html_text += \"</p><br>\"\n",
    "    #html_text += \"<p style='font-size: large'><b>Classified as:</b> \"\n",
    "    #html_text += label2id[label] \n",
    "    #html_text += \"</p>\"\n",
    "    \n",
    "    # Display text enriched with attention scores \n",
    "    display(HTML(html_text))\n",
    "    \n",
    "    # PLOT EMOTION SCORES\n",
    "    _labels = ['sincere', 'insincere']\n",
    "    probs = np.zeros(2)\n",
    "    probs[1] = label_probs\n",
    "    probs[0] = 1- label_probs\n",
    "    plt.figure(figsize=(5,2))\n",
    "    plt.bar(np.arange(len(_labels)), probs.squeeze(), align='center', alpha=0.5, color=['black', 'red', 'green', 'blue', 'cyan', \"purple\"])\n",
    "    plt.xticks(np.arange(len(_labels)), _labels)\n",
    "    plt.ylabel('Scores')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
